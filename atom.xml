<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> - Articles</title>
    <description>machine learning research notes</description>
    <link>
    https://rauleun.github.io</link>
    
      
      <item>
        <title>RandLA-Net 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/1911.11236&quot;&gt;Hu, Qingyong, et al. “Randla-net: Efficient semantic segmentation of large-scale point clouds.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Fri, 23 Apr 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/RandLA-Net</link>
        <guid isPermaLink="true">https://rauleun.github.io/RandLA-Net</guid>
      </item>
      
    
      
      <item>
        <title>Momentum Contrast(MoCo) v3 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/2104.02057&quot;&gt;Chen, Xinlei, Saining Xie, and Kaiming He. “An Empirical Study of Training Self-Supervised Visual Transformers.” arXiv preprint arXiv:2104.02057 (2021).&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Fri, 16 Apr 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/MoCo_v3</link>
        <guid isPermaLink="true">https://rauleun.github.io/MoCo_v3</guid>
      </item>
      
    
      
      <item>
        <title>Momentum Contrast(MoCo) v1 &amp; v2 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/1911.05722&quot;&gt;He, Kaiming, et al. “Momentum contrast for unsupervised visual representation learning.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://arxiv.org/abs/2003.04297&quot;&gt;Chen, Xinlei, et al. “Improved baselines with momentum contrastive learning.” arXiv preprint arXiv:2003.04297 (2020).&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Wed, 14 Apr 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/MoCo</link>
        <guid isPermaLink="true">https://rauleun.github.io/MoCo</guid>
      </item>
      
    
      
      <item>
        <title>SimCLR v1 &amp; v2 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/2002.05709&quot;&gt;Chen, Ting, et al. “A simple framework for contrastive learning of visual representations.” International conference on machine learning. PMLR, 2020.&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://arxiv.org/abs/2006.10029&quot;&gt;Chen, Ting, et al. “Big self-supervised models are strong semi-supervised learners.” arXiv preprint arXiv:2006.10029 (2020).&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Sat, 10 Apr 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/SimCLR</link>
        <guid isPermaLink="true">https://rauleun.github.io/SimCLR</guid>
      </item>
      
    
      
      <item>
        <title>Point Transformer 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/2012.09164&quot;&gt;Zhao, Hengshuang, et al. “Point transformer.” arXiv preprint arXiv:2012.09164 (2020).&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Tue, 02 Mar 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/Point-Transformer</link>
        <guid isPermaLink="true">https://rauleun.github.io/Point-Transformer</guid>
      </item>
      
    
      
      <item>
        <title>KPConv - Flexible and Deformable Convolution for Point Clouds 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://openaccess.thecvf.com/content_ICCV_2019/html/Thomas_KPConv_Flexible_and_Deformable_Convolution_for_Point_Clouds_ICCV_2019_paper.html&quot;&gt;Thomas, Hugues, et al. “Kpconv: Flexible and deformable convolution for point clouds.” Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Sun, 07 Feb 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/KPConv</link>
        <guid isPermaLink="true">https://rauleun.github.io/KPConv</guid>
      </item>
      
    
      
      <item>
        <title>Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://openaccess.thecvf.com/content_cvpr_2018/html/Landrieu_Large-Scale_Point_Cloud_CVPR_2018_paper.html&quot;&gt;Landrieu, Loic, and Martin Simonovsky. “Large-scale point cloud semantic segmentation with superpoint graphs.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Fri, 29 Jan 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/Superpoint-Graphs</link>
        <guid isPermaLink="true">https://rauleun.github.io/Superpoint-Graphs</guid>
      </item>
      
    
      
      <item>
        <title>Graph Attention Convolution for Point Cloud Semantic Segmentation 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Graph_Attention_Convolution_for_Point_Cloud_Semantic_Segmentation_CVPR_2019_paper.pdf&quot;&gt;Wang, Lei, et al. “Graph attention convolution for point cloud semantic segmentation.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Wed, 27 Jan 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/GACnet</link>
        <guid isPermaLink="true">https://rauleun.github.io/GACnet</guid>
      </item>
      
    
      
      <item>
        <title>PointNet++ - Deep Hierarchical Feature Learning on Point Sets in a Metric Space 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://papers.nips.cc/paper/2017/file/d8bf84be3800d12f74d8b05e9b89836f-Paper.pdf&quot;&gt;Qi, Charles Ruizhongtai, et al. “Pointnet++: Deep hierarchical feature learning on point sets in a metric space.” Advances in neural information processing systems. 2017.&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Thu, 21 Jan 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/PointNet++</link>
        <guid isPermaLink="true">https://rauleun.github.io/PointNet++</guid>
      </item>
      
    
      
      <item>
        <title>Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/1704.02901&quot;&gt;Simonovsky, Martin, and Nikos Komodakis. “Dynamic edge-conditioned filters in convolutional neural networks on graphs.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.
&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Wed, 20 Jan 2021 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/Edge-Conditioned-Convolution</link>
        <guid isPermaLink="true">https://rauleun.github.io/Edge-Conditioned-Convolution</guid>
      </item>
      
    
      
      <item>
        <title>BERT - Pretraining of Deep Bidirectional Transformers for Language Understanding 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;Devlin, Jacob, et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” arXiv preprint arXiv:1810.04805 (2018).
&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Tue, 03 Nov 2020 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/BERT</link>
        <guid isPermaLink="true">https://rauleun.github.io/BERT</guid>
      </item>
      
    
      
      <item>
        <title>EfficientDet - Scalable and Efficient Object Detection 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.pdf&quot;&gt;Tan, Mingxing, Ruoming Pang, and Quoc V. Le. “Efficientdet: Scalable and efficient object detection.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.
&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Sat, 26 Sep 2020 09:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/EfficientDet</link>
        <guid isPermaLink="true">https://rauleun.github.io/EfficientDet</guid>
      </item>
      
    
      
      <item>
        <title>(DETR) End-to-End Object Detection with Transformers 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/2005.12872&quot;&gt;Carion, Nicolas, et al. “End-to-End Object Detection with Transformers.” arXiv preprint arXiv:2005.12872 (2020). &lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Mon, 14 Sep 2020 20:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/DETR</link>
        <guid isPermaLink="true">https://rauleun.github.io/DETR</guid>
      </item>
      
    
      
      <item>
        <title>Attention is All You Need 리뷰</title>
        
          <description>&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot;&gt;Vaswani, Ashish, et al. “Attention is all you need.” Advances in neural information processing systems. 2017.&lt;/a&gt;&lt;/p&gt;

</description>
        
        <pubDate>Mon, 07 Sep 2020 20:00:00 +0900</pubDate>
        <link>
        https://rauleun.github.io/attention-is-all-you-need</link>
        <guid isPermaLink="true">https://rauleun.github.io/attention-is-all-you-need</guid>
      </item>
      
    
  </channel>
</rss>
