<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="https://rauleun.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://rauleun.github.io/" rel="alternate" type="text/html" /><updated>2021-04-15T11:36:00+09:00</updated><id>https://rauleun.github.io/</id><title type="html">RE Tech Archive</title><subtitle>machine learning research notes</subtitle><entry><title type="html">Momentum Contrast(MoCo) v1 &amp;amp; v2 리뷰</title><link href="https://rauleun.github.io/MoCo" rel="alternate" type="text/html" title="Momentum Contrast(MoCo) v1 &amp; v2 리뷰" /><published>2021-04-14T09:00:00+09:00</published><updated>2021-04-14T09:00:00+09:00</updated><id>https://rauleun.github.io/MoCo</id><content type="html" xml:base="https://rauleun.github.io/MoCo">&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/1911.05722&quot;&gt;He, Kaiming, et al. “Momentum contrast for unsupervised visual representation learning.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://arxiv.org/abs/2003.04297&quot;&gt;Chen, Xinlei, et al. “Improved baselines with momentum contrastive learning.” arXiv preprint arXiv:2003.04297 (2020).&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;오늘은 FAIR에서 2020년에 CVPR에 발표한 &lt;em&gt;&lt;strong&gt;Momentum contrast for unsupervised visual representation learning (MoCo)&lt;/strong&gt;&lt;/em&gt; 논문과 그 후속 연구로 약간의 성능을 개선한 &lt;em&gt;&lt;strong&gt;Improved baselines with momentum contrastive learning (MoCo v2)&lt;/strong&gt;&lt;/em&gt; 논문에 대해 리뷰를 진행해보겠습니다.&lt;/p&gt;

&lt;p&gt;MoCo는 SimCLR과 마찬가지로 contrastive loss를 이용한 unsupervised learning 방법입니다. 다만 negative pair를 추출하는 방식이나, query encoder를 update하는 방식에 약간의 차이가 있습니다. SimCLR에 대한 리뷰를 먼저 읽고 오시면 이해하기 좀 더 수월할 것 같습니다. 그럼 MoCo에 대한 소개를 시작하겠습니다!&lt;/p&gt;

&lt;h2 id=&quot;contrastive-learning-as-dictionary-look-up&quot;&gt;Contrastive Learning as Dictionary Look-up&lt;/h2&gt;

&lt;p&gt;Contrastive learning이란 데이터의 label 없이 네트워크 모델을 학습하는 unsupervised learning의 일종으로, positive pair 간의 유사도는 높이고 negative pair 간의 유사도는 낮추는 방향으로 모델을 학습하는 방법입니다. Contrastive learning을 수행하려면 positive pair와 negative pair를 추출해야 하는데, SimCLR에서는 하나의 batch 안에서 positive pair과 negative pair를 추출하였습니다. 이와 달리 MoCo에서는 특정 크기의 dictionary를 정의하여 sample들의 key값을 저장해두고, query와 matching되는 값을 positive key로, 나머지를 negative key로 분류하여 추출하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/1-moco.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MoCo의 구조는 위의 그림과 같습니다. 각 이미지들에 대한 query와 key는 각각 query encoder와 key encoder를 이용하여 생성합니다. Encoder는 CNN 기반의 네트워크를 활용하며 MoCo에서는 ResNet을 활용하였습니다. 한 이미지에서 생성한 query는 같은 이미지로부터 생성한 key와 positive pair를 구성하고, 다른 이미지에서 생성한 key와 negative pair를 구성합니다.&lt;/p&gt;

&lt;p&gt;Contrastive loss를 이용하여 안정적으로 학습하려면 충분한 개수의 negative pair이 꼭 필요합니다. MoCo에서는 충분히 큰 크기의 dictionary를 queue 형태로 두고, dictionary에서 negative sample들을 추출하였습니다. Dictionary의 크기는 일반적으로 batch size보다 크며 논문에서는 기본값으로 65536개를 이용하였습니다. 만약 256개의 batch 단위로 학습을 진행한다면, 하나의 입력 이미지에 대해 query와 key를 생성하여 positive pair를 이루고 dictionary에 이미 들어있는 65536개의 key와 negative pair를 이루게 됩니다. Dictionary는 queue 구조를 가지고 있기 때문에 256개의 batch에 대해 학습이 완료되고 나면, 학습 과정에서 생성된 256개의 key들이 가장 오래된 256개의 key들을 대체하게 됩니다. 학습에 따라 dictionary의 구성이 update되기 때문에, 이를 dynamic dictionary라고 부르기도 합니다.&lt;/p&gt;

&lt;p&gt;하지만 queue 구조의 큰 dictionary를 이용하게 되면, key encoder를 학습하는 과정에서 수많은 negative sample들에 대해 gradient를 전파해야하기 때문에 학습이 어려워집니다. 이를 해결하기 위해 key encoder를 따로 학습하지 않고(stop gradiet), 학습된 query encoder를 그대로 가져와서 이용해보았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/5-result-momentum.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 표에서 momentum=0 인 경우가 매 batch마다 query encoder를 그대로 key encoder로 이용하여 학습한 결과입니다. Loss가 전혀 수렴하지 않아서 학습이 되지 않았는데, 논문에서는 빠르게 변화하는 query encoder를 그대로 이용해서 key를 계산하게 되면 key값들의 consistency가 유지되지 않기 때문이라고 설명합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/3-momentum-update.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이를 해결하기 위해, momentum update를 적용시켜 key encoder를 천천히 진화시키는 방법을 이용했습니다. 위의 표에서 볼 수 있듯, 0.999의 momentum 값을 이용했을 때 가장 높은 정확도를 얻을 수 있었습니다. 이렇듯 dictionary 내의 key 구성이 consistent해야 학습이 안정적으로 진행되었습니다.&lt;/p&gt;

&lt;p&gt;MoCo에서 강조하는 것은 크고 일관성 있는 dictionary의 구성입니다. MoCo는 queue 형태의 dictionary와 momentum update를 이용한 key encoder의 변화로 이를 가능하게 만들었습니다. 그렇다면 MoCo가 유사한 기존의 방법들과 어떻게 다른지에 대해 자세히 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;comparison-to-previous-mechanisms&quot;&gt;Comparison to previous mechanisms&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/2-comparison-moco.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;논문에서는 MoCo를 기존의 두 가지 방법과 비교하고 있습니다. &lt;em&gt;end to end&lt;/em&gt; 라고 부르는 첫 번째 방법은, key encoder도 query encoder와 마찬가지로 똑같이 학습시켜주는 방법입니다. 이 경우에는 queue 형태의 dictionary를 사용하는 것이 아니라, mini-batch에 해당하는 sample들을 batch로 이용했기 때문에 GPU memory 크기에 제약을 받을 수 밖에 없게 됩니다. 따라서 MoCo에 비해 상대적으로 적은 수의 negative sample밖에 이용할 수 없고, large-batch optimization에 대한 issue도 문제가 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Memory bank&lt;/em&gt; 를 이용하는 두 번째 방법은, 데이터셋에 존재하는 모든 sample들의 representation을 memory bank에 넣어두고, 임의로 몇 개의 sample을 골라 dictionary를 구성하는 방법입니다. 이후 query에 해당하는 sample들로 memory bank를 update하면서 학습을 진행합니다. 이 경우에 memory bank 안의 key들이 빠르게 변하는 query encoder의 결과값으로 update 되기 때문에, dictionary가 inconsistent해지고 학습이 제대로 되지 않았습니다. 이를 해결하기 위해 key를 update할 때 momentum update를 적용하였는데, encoder가 아니라 key값 자체가 update되는 것이기 때문에 한 epoch 뒤의 encoder output에 대한 값을 이용하게 되고, 마찬가지로 inconsistency 문제가 발생하였습니다.&lt;/p&gt;

&lt;p&gt;MoCo는 위 두 방법과 달리 queue 구조를 활용한 dictionary를 이용하기 때문에 충분한 양의 negative sample로 학습할 수 있습니다. 또한 memory-efficient하고 데이터셋의 크기가 클 때도 안정적으로 학습할 수 있습니다. (memory bank의 경우 데이터셋의 크기가 너무 크면, update 주기가 길어지기 때문에 학습이 불안정합니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/4-result-momentum.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림은 세 방법에 대한 결과를 나타냅니다. &lt;em&gt;End-to-end&lt;/em&gt; 방법은 MoCo와 비슷한 성능을 보이지만, 1024 이상으로 batch size를 키울 수 없었습니다. &lt;em&gt;Memory bank&lt;/em&gt; 방법은 inconsistency issue로 인해 낮은 성능을 보여주었습니다.&lt;/p&gt;

&lt;h2 id=&quot;momentum-contrast&quot;&gt;Momentum Contrast&lt;/h2&gt;

&lt;p&gt;MoCo는 입력 이미지에 대해 random data augmentation을 거친 후 query 및 key encoder에 넣어주었습니다. Random data augmentation은 random resize/ random color jittering/ random horizontal flip/ random grayscale conversion의 순서로 구성했습니다.&lt;/p&gt;

&lt;p&gt;Constrastive learning을 위한 loss function은 InfoNCE라고 불리는 위와 같은 형태의 함수를 이용했습니다. &lt;em&gt;q&lt;/em&gt; 는 query를, &lt;em&gt;k+&lt;/em&gt; 는 positive key를, &lt;em&gt;t&lt;/em&gt; 는 temperature htper-parameter를 의미합니다. &lt;em&gt;k+&lt;/em&gt; 를 제외한 나머지 &lt;em&gt;k&lt;/em&gt; 는 negative sample입니다.&lt;/p&gt;

&lt;p&gt;위 함수는 query와 positive key가 유사하고, 나머지 negative key와는 유사하지 않을때 값이 작아지는 cross-entropy 기반의 loss입니다. 유사도는 내적연산으로 계산합니다.&lt;/p&gt;

&lt;p&gt;또한 multi-gpu device로 학습하는 과정에서,  ResNet 구조 내부의 batch normalization 과정을 거칠 때 device별로 batch normalization을 해주었습니다. 이 때 데이터가 device 별로 편향되어서 batch normalization 과정에서 전체 data에 대한 정보를 잃는 현상이 있었습니다. 이를 해결하기 위해 MoCo에서는 device에 데이터를 분배할 때 random한 순서로 넣어주는 &lt;em&gt;shuffling batch normalization&lt;/em&gt; 방법을 이용하였습니다.&lt;/p&gt;

&lt;p&gt;MoCo는 ImageNet-1M 데이터셋과 Instagram-1B 데이터셋을 이용하여 학습하였습니다. 학습은 256개의 batch 단위로 진행되었고,  65536개의 sample을 넣을 수 있는 queue 구조의 dictionary를 이용하였습니다. Encoder 구조는 ResNet-50을 이용하였고 200 epochs만큼 학습해주었습니다.&lt;/p&gt;

&lt;h2 id=&quot;result&quot;&gt;Result&lt;/h2&gt;

&lt;p&gt;학습된 MoCo 모델은 일반적으로 unsupervised learning 알고리즘을 평가할 때 이용하는 linear evaluation 방법으로 성능을 측정하였습니다. Linear evaluation은 학습된 모델을 고정(freeze)하고 그 위에 linear classifier를 얹어서 학습 후 결과를 측정하는 방법입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/6-result-eval.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;assets/images/210414-MoCo/7-result-eval.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림은 linear evaluation 결과를 비교하고 있는데요. MoCo가 발표된 당시 기준으로 다른 unsupervised learning 방법과 비교해 SOTA의 성능을 보여주었습니다. (하지만 얼마 지나지 않아 더 좋은 성능을 보이는 모델-SimCLR이 발표되었습니다.)&lt;/p&gt;

&lt;p&gt;논문에서는 또한 MoCo가 object detection이나 segmentation 등 다른 task의 backbone 모델로 이용되었을 때 어떤 결과를 보이는지에 대해서도 실험했습니다. Pascal VOC와 COCO 데이터셋을 이용하여 실험했는데, Pascal VOC 데이터셋에 대한 결과만 보여드리겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/8-result-ap.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MoCo는 scratch부터 학습하거나, supervised 방식으로 학습한 pretraining 모델을 이용한 경우보다 좋은 object detection 성능을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/9-result-comparison.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MoCo는 &lt;em&gt;end-to-end&lt;/em&gt; 나 &lt;em&gt;memory bank&lt;/em&gt;와 비교했을 때도 AP 기준 더 높은 성능을 보였습니다. Classification task에 대해 더 유용한 visual representation이 object detection task에서도 더 뛰어난 결과를 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/10-result-unsupervised.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 RelPos, Jigsaw 등의 다른 unsupervised learning 알고리즘보다도 object detection task에서 뛰어난 성능을 보여주었습니다. Pre-training을 여러 데이터셋에 대해 진행했는데, 모두 같은 경향성을 보였습니다.&lt;/p&gt;

&lt;h2 id=&quot;moco-v2&quot;&gt;MoCo v2&lt;/h2&gt;

&lt;p&gt;저자들은 MoCo의 짧았던 전성기가 아쉬웠던지 곧이어  몇 가지 항목을 개선한 MoCo v2를 발표했습니다.  MoCo v2는 SimCLR을 벤치마킹해서 기존의 MoCo를 세 가지 부분에서 개선했는데요. 우선 MLP 기반의 projection head를 추가하였고, encoder에 들어가는 sample들의 data augmentation 구성을 최적화했으며, cosine learning rate schedule을 추가하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/12-result-mocov2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MLP projection head&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;기존 MoCo와 SimCLR의  encoder network는 모두 ResNet을 기반으로 하고있지만, 약간의 구조적 차이가 존재합니다. MoCo는 ResNet의 마지막 global average-pooling layer와 연결된 linear layer(출력차원=128)까지를 기본 encoder로 이용했고, SimCLR은 global average-pooling layer까지를 base encoder로 이용하고 뒤에 MLP 구조의 projection head를 연결하였습니다.&lt;/p&gt;

&lt;p&gt;SimCLR의 핵심적인 아이디어 중 하나가, 학습에만 projection head를 사용하고 학습이 완료된 후에는 projection head를 제외한 구조로 visual representation을 추출하는 것인데요. MoCo는 이러한 SimCLR의 구조를 그대로 차용하여 실험했습니다. 실험 결과 MLP projection head를 이용하기 전보다 5.6%의 linear evaluation 성능이 향상되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data augmentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SimCLR에서는 다양한 data augmentation의 조합에 따른 성능을 비교하여, augmentation의 구성을 결정했습니다. MoCo v2도 여러가지 실험을 통해, 기존의 augmentation에 Gaussian blurring을 추가하였습니다. 추가한 결과 기존에 비해 2.8%의 성능이 향상되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cosine learning rate schedule&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SimCLR에서는 cosine learning rate scheduling 방법을 이용해 학습을 진행했습니다. MoCo v2에서도 기존의 개선 방안들에 cosine decay learning rate를 추가하여 학습했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210414-MoCo/13-result-mocov2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과적으로 위 세가지 방법을 모두 이용하여 학습 시간을 충분히 늘려주었을 때, 71.1%로 SOTA의 성능을 보여주었습니다.또한 MoCo는 SimCLR과 비교해서 적은 batch size로도 학습이 가능하기 때문에 memory-efficiency 측면에서도 우세한 모습을 보여주었습니다.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;MoCo는 크고 일관성 있는 negative sample dictionary를 구성해 학습 성능을 높이는데 초점을 맞춘 contrastive learning 기반의 모델입니다. 다양한 downstream task에 대한 unsupervised learning 기반 모델의 활용 가능성 또한 충분히 보여준 연구라고 생각합니다.&lt;/p&gt;

&lt;p&gt;MoCo와 SimCLR은 축구계의 메시와 호날두처럼 서로 긍정적인 경쟁을 하고 있는 것으로 보입니다. 두 논문이 서로 발전적으로 진화하는 모습을 지켜보는 것도 상당히 즐거울 것 같습니다. 이만 이번 리뷰는 마무리하겠습니다. 긴 글 읽어주셔서 감사합니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1911.05722&quot;&gt;https://arxiv.org/abs/1911.05722&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2003.04297&quot;&gt;https://arxiv.org/abs/2003.04297&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="CV" /><category term="CV" /><summary type="html">원문 : He, Kaiming, et al. “Momentum contrast for unsupervised visual representation learning.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020. &amp;amp; Chen, Xinlei, et al. “Improved baselines with momentum contrastive learning.” arXiv preprint arXiv:2003.04297 (2020).</summary></entry><entry><title type="html">SimCLR v1 &amp;amp; v2 리뷰</title><link href="https://rauleun.github.io/SimCLR" rel="alternate" type="text/html" title="SimCLR v1 &amp; v2 리뷰" /><published>2021-04-10T09:00:00+09:00</published><updated>2021-04-10T09:00:00+09:00</updated><id>https://rauleun.github.io/SimCLR</id><content type="html" xml:base="https://rauleun.github.io/SimCLR">&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/2002.05709&quot;&gt;Chen, Ting, et al. “A simple framework for contrastive learning of visual representations.” International conference on machine learning. PMLR, 2020.&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://arxiv.org/abs/2006.10029&quot;&gt;Chen, Ting, et al. “Big self-supervised models are strong semi-supervised learners.” arXiv preprint arXiv:2006.10029 (2020).&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/1-SimCLR.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 Google Research에서 2020년 각각 ICML과 NIPS에 발표한 &lt;strong&gt;&lt;em&gt;A simple framework for contrastive learning of visual representations (SimCLR)&lt;/em&gt;&lt;/strong&gt; 논문과 &lt;strong&gt;&lt;em&gt;Big self-supervised models are strong semi-supervised learners (SimCLR v2)&lt;/em&gt;&lt;/strong&gt; 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;후자의 논문은 전자에서 제안한 SimCLR 기반 모델의 성능을 개선한 후속 연구를 담고 있습니다. 따라서 이 글의 순서는 SimCLR의 개념을 소개하는 전자의 논문을 먼저 리뷰하고, SimCLR의 성능을 고도화한 후자의 논문을 이어서 리뷰하겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;simclr-v1&quot;&gt;&lt;em&gt;SimCLR v1&lt;/em&gt;&lt;/h1&gt;

&lt;p&gt;첫 번째 논문은 이미지 데이터의 정답 label이 없는 상황에서 효과적으로 visual representation 을 추출하는 SimCLR이라는 이름의 unsupervised learning algorithm을 소개하고 있습니다. SimCLR은 data augmentation을 통해 얻은 positive/negative sample들에 대해 contrastive learning을 적용시켰으며, 성능 측면에서 supervised learning으로 학습한 모델들에 준하는 모습을 보여주었습니다. 그럼 SimCLR을 지금부터 파헤쳐보겠습니다!&lt;/p&gt;

&lt;h2 id=&quot;contrastive-learning-framework&quot;&gt;Contrastive Learning Framework&lt;/h2&gt;

&lt;p&gt;Unsupervised learning이란 데이터의 label 없이 네트워크 모델을 학습하는 것을 의미합니다. 이전에 Computer vision 분야에서는 이미지를 임의로 회전시킨 후 모델이 회전 방향을 맞추게끔 학습시키거나, 이미지를 잘라 zigsaw 퍼즐을 만든 후 모델이 퍼즐을 풀 수 있게끔 모델을 학습했습니다. 이렇게 모델을 학습하기 위해 정의한 새로운 형태의 문제를 pretext task 라고 부릅니다. Pretext task를 통해 학습하는 방식은 어느 정도의 성능을 보여주긴 했지만, 해당 pretext task를 잘 풀 게끔 학습되었을 뿐 이미지의 일반적인 시각적 특징을 잡아내지는 못하는 모습을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;이를 해결하기 위해 최근에는 contrastive learning 기반의 방식들이 많이 연구되고 있습니다. Contrastive learning이란 positive pair끼리는 같게, negative pair끼리는 다르게 구분하면서 모델을 학습하는 방식입니다. 예를 들면 노랑이라는 키워드(query)가 주어지고 사과/바나나/딸기라는 보기(key)가 있을 때, 노랑-바나나를 연결하고 사과/딸기와는 연결되지 않게 학습하는 방법입니다. 위 방식은 이전에 발표된 여러 연구들(CPC, CMC 등)에서 뛰어난 성능을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/2-framework.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SimCLR은 각 이미지에 서로 다른 두 data augmentation들을 적용하여, 같은 이미지로부터 나온 결과들은 positive pair로 정의하고 서로 다른 image로부터 나온 결과들은 negative pair로 정의하는 형태로 contrastive learning 방식을 적용하였습니다. 위의 그림에서 보면, 하나의 이미지(x)가 서로 다른 두 개의 augmentation 변환을 거쳐 두 개의 이미지(xi, xj)로 나눠집니다. 이렇게 변환된 두 이미지는 같은 이미지로부터 얻었기 때문에 positive pair로 정의합니다. 만약 또다른 이미지인 y로부터 yi, yj의 변환된 이미지가 나왔다고 한다면 xi과 yi(또는 yj)는 서로 다른 이미지로부터 얻었기 때문에 negative pair로 정의합니다.&lt;/p&gt;

&lt;p&gt;변환된 각 이미지들(xi, xj)은 CNN기반의 네트워크(f)를 통과하여 visual representation embedding vector(hi, hj)로 변환됩니다. 이러한 representation vector를 생성하는 network를 base encoder라고 부르며 논문에서는 ResNet을 base encoder로 이용하였습니다. Visual representation vector는 MLP 기반의 네트워크(g)를 통과하여 변환되고, 변환된 output(zi, zj)를 이용하여 contrastive loss를 계산합니다. MLP 기반의 네트워크는 projection head라고 부르며, 두 개의 linear layer 사이에 ReLU activation function을 넣은 구조로 구성되어 있습니다.&lt;/p&gt;

&lt;p&gt;Encoder 및 projection head는 batch 단위로 학습하게 되는데, 만약 N의 batch size를 이용하게 된다면 각각 data augmentation을 거쳐서 2N개의 sample을 얻을 수 있습니다. 이렇게 되면 각 sample 별로 1쌍의 positive pair와 2N-2쌍의 negative pair를 구성할 수 있게 됩니다. 논문에서는 positive pair 간의 similarity는 높이고, negative pair 간의 similarity는 최소화하는 형태의 loss function을 제안하여 학습에 활용하였습니다. 해당 loss function은 NT-Xent라는 이름으로 불리며, 아래와 같은 방식으로 계산됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/3-augmentations.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 contrastive learning 방식으로 학습을 진행할 때, 1.좋은 퀄리티를 가지며 2.충분히 많은 양의 negative pair가 필요하다고 알려져 있습니다. 학습은 batch 단위로 진행되기 때문에, 많은 양의 negative pair를 구성하기 위해서는 큰 batch size를 이용해서 학습해야 합니다. 이를 위해 SimCLR은 기본적으로 4096의 batch size(총 8192개의 sample)를 이용하여 학습했으며 빠른 학습을 위해 128 코어의 google cloud TPU를 사용했다고 합니다. 또한 SGD나 Momentum optimizer가 아닌, 큰 크기의 batch size로 학습할 때 적절하다고 알려진 LARS optimizer를 이용하여 multi-device(분산학습)으로 학습하였습니다. Batch normalization을 적용할 떄는, device 별로 평균과 표준 편차를 계산하여 적용하는 것이 아니라, 모든 device에서의 평균/표준편차 값들을 통합해서 적용하였습니다. 이렇게 하면 positive sample이 포함된 device와 negative sample만으로 구성된 device들 간의 분포를 같게 normalize하게 되어 batch normalization 과정에서 발생하는 정보 손실을 최소화할 수 있습니다.&lt;/p&gt;

&lt;p&gt;논문에서는 위에서 제안한 contrastive learning 기반의 framework로 다양한 실험을 진행했습니다. 기본적인 unsupervised learning 과정은 모두 ImageNet ILSVRC-2012 데이터셋으로 진행하였고, 학습한 encoder를 고정(freeze)시키고 그 위에 linear classifier를 얹어서 정확도를 측정하는 linear evaluation 방식으로 모델을 평가하였습니다. 그 외에 encoder를 고정시키지 않고 학습 가능하게 만들어서 평가하는 fine-tuning 방식이나, 다른 dataset을 이용해서 모델 변수를 조정하는 transfer learning 방식으로 SimCLR encoder를 평가하였습니다.&lt;/p&gt;

&lt;p&gt;지금까지 대략적으로 SimCLR에 대해 소개했습니다. 지금부터는 SimCLR에서 어떤 data augmentation 방법을 사용했는지, 왜 projection head를 제외한 encoder만 실제로 이용하는지 등에 대해 조금 더 자세히 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;data-augmentation-for-contrastive-representation-learning&quot;&gt;Data Augmentation for Contrastive Representation Learning&lt;/h2&gt;

&lt;p&gt;SimCLR에서는 우리가 supervised learning에서 일반적으로 사용하던 data augmentation 방법들을 이용하여 positive pair와 negative pair를 생성하였습니다. Data augmentation을 이용하기 전에는 두 종류의 sample을 만들기 위해 서로 다른 모델 구조를 가진 네트워크를 이용했다고 하는데요. 예를 들면 receptive field가 다른 두 CNN을 이용하여 하나는 local한 정보 위주로 추출하고, 다른 하나는 global한 정보 위주로 추출하여 contrastive loss를 적용하는 식이었다고 합니다. 하지만 이는 data augmentation으로 random crop을 하는 것과 같은 효과를 보이는데요, data augmentation 기반의 방법으로 훨씬 더 간단하게 sample을 추출할 수 있는 것입니다.&lt;/p&gt;

&lt;p&gt;그렇다면 어떤 data augmentation 방법들을 이용해야 최적의 visual representation을 학습할 수 있을까요? SimCLR에서는 위의 그림에서 보이듯 cropping이나 resizing, rotating, cutout 등 이미지의 공간적/기하학적 구조를 변형하는 data augmentation 방법과 color dropping, jittering, Gaussian blurring, Sobel filtering 등 이미지의 색상을 왜곡하는 data augmentation 방법들을 제시하였습니다. 사실 ImageNet 데이터셋의 이미지들은 서로 다른 크기를 가지고 있기 떄문에 학습 전에 항상 crop/resize 과정을 거쳐서 변환해주었다고 하는데요. SimCLR에서는 crop/resize 과정을 기본으로 하고, 한쪽 augmentation branch에서는 테스트해보고자 하는 다른 augmentation 방법들을 추가해주고 다른 한쪽 branch는 그대로 둔 채 학습을 진행하여 성능을 비교했습니다. 이러한 비대칭적인 구성은 다른 branch에도 augmentation 과정을 추가했을 때보다 성능이 낮을 수 있는데요, 그럼에도 불구하고 공정한 비교를 위해 이러한 방식을 선택했다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/4-augmentations-comparison.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;총 7가지의 data augmentation 방법을 하나 또는 두개 이어붙여서 성능을 측정하였는데요, 결과적으로 하나의 augmentation 만으로는 좋은 성능을 달성하기 어려웠고, 여러 augmentation을 더해주었을 때 predictive task의 난이도가 높아지면서 representation quality가 증가했다고 합니다. 두 가지 augmentation을 이어 붙인 경우에는 위의 그림에서 알 수 있듯 random crop과 random color distortion을 이어붙인 경우에 가장 좋은 성능을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/5-color-distribution.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;특히 논문에서는 Color distortion이 꼭 필요한 이유에 대해서도 나름의 분석을 보여주었는데요. Color distortion 없이 random crop만 진행한 경우에는 augmentation branch를 통해서 얻은 sample들이 위의 historgram에서 보이듯 서로 같은 color distribution을 공유하고 있었고, 결국 네트워크가 시각적인 특징을 찾아내는 것이 아닌 색 배합만을 찾아내어 낮은 representation quality를 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/6-color-distortion.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 data augmentation의 세기를 바꾸어가며 모델의 성능을 측정해보기도 하였는데요, 위의 표를 보시면 color distortion을 강하게 가할수록 contrastive prediction task의 난이도가 증가하여 visual representation을 더 잘 추출하게끔 학습하였습니다. 심지어는 supervised learning에 도움이 되지 않는 강도의 augmentation도 SimCLR에서는 성능 향상에 기여하는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;model-architecture-of-simclr&quot;&gt;Model Architecture of SimCLR&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/7-result-le.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림은 SimCLR과 supervised learning의 학습 방법을 다양한 크기의 모델에 적용시키며 linear evaluation 성능을 통해 비교한 것입니다. Supervised learning과 마찬가지로 SimCLR도 모델의 크기가 커질수록 학습 성능이 증가하는 경향을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/9-projection-head.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 non-linear projection head를 통해서 contrastive loss를 계산하는 구조 역시 linear projection head나 projection head를 아예 이용하지 않을 때보다 항상 좋은 성능을 낸다는 것을 보여주었습니다. 이 때 projection head의 output dimension은 성능에 크게 영향을 주지 않는 것이 확인되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/16-t-sne.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Projection head는 학습 성능을 높여주었지만, projection head를 통해서 얻은 output vector는 base encoder의 output보다 시각적인 특징을 잘 표현하지 못하였습니다. 위의 그림은 10개의 클래스에 대한 base encoder와 projection head의 output vector를 t-SNE 방법으로 군집화한 것인데요. Base encoder로부터 나온 vector들이 클래스 별로 훨씬 더 잘 구분되는 것을 확인할 수 있습니다. 논문에서는 contrastive learning을 통해서 학습한 정보들이 projection head를 지나면서 소실되기 때문이라고 이를 설명하는데요. 이를 보여주기 위해서 contrastive prediction task를 두 벡터들이 얼마나 잘 맞추는지에 대한 실험을 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/10-projection-head-loose-information.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 결과를 보시면 projection head의 output vector는 base encoder의 output보다 rotation이나 gaussian noise, sobel filtering 등의 정보를 많이 담고 있지 않은 것을 볼 수 있습니다. 일반적인 downstream task가 이러한 시각적인 정보들을 기반으로 해결할 수 있는 task들이라고 한다면, base encoder에서 나온 vector를 visual representation으로 활용하는 것이 논리적으로 맞는 선택인 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;loss-function-and-batch-size&quot;&gt;Loss Function and Batch Size&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/8-loss-functions.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SimCLR에서는 cross-entropy 기반의 NT-Xent loss function을 이용하여 contrastive learning을 진행합니다. 논문에서는 NT-Xent loss와 기존 Contrastive learning에서 많이 사용되는 NT-Logistic, Margin triplet loss를 비교하면서 loss function 선정의 정당성을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/11-loss-comparison.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;NT-Xent loss는 cross entropy loss를 기반으로 하기 때문에 negative sample들이 기준 sample과 얼마나 다른지에 대한 크기를 반영하고 있고, 결과적으로 좋은 성능을 보여준다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/12-batch-size.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Contrastive learning은 안정적인 학습을 위해 충분한 양의 negative sample이 필수적입니다. Negative sample의 개수는 batch size와 비례하기 때문에, SimCLR을 학습할 때 batch size를 키울수록 모델의 성능이 증가하는 경향을 보여주었습니다. 또한 학습 과정에 random augmentation이 포함되어 있기 때문에 학습 시간이 길어질수록 충분한 양의 negative sample을 볼 수 있고, 성능에 대한 유의미한 경향성을 찾을 수 있었습니다.&lt;/p&gt;

&lt;h2 id=&quot;comparison-with-sota&quot;&gt;Comparison with SOTA&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/13-result-le-table.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SimCLR은 1. 학습된 모델을 고정(freeze)하고 위에 linear classifier를 얹어서 성능을 평가하는 &lt;em&gt;linear evaluation&lt;/em&gt;, 2.학습된 모델과 linear classifier를 모두 learnable한 상태로 학습하는 &lt;em&gt;fine-tuning&lt;/em&gt;, 3.학습된 모델을 다른 종류의 dataset에 대하여 learnable한 상태로 학습하는 &lt;em&gt;transfer learning&lt;/em&gt; 의 세 가지 방법으로 평가하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/14-result-ft.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;우선 기존의 self-supervised 방법들과 비교했을 때 SOTA의 성능을 보여주었습니다. 위의 두 그림은 Linear evaluation과 적은 dataset에 대한 fine-tuning 평가의 결과입니다. 두 방법들 모두 좋은 성능을 보여주었고, fine-tuning의 경우에는 같은 모델의 supervised learning 학습 결과보다도 좋은 성능을 보여주었습니다. (단, SimCLR의 경우 이미 pre-training된 모델을 fine-tuning 한 것이고 supervised learning의 경우 scratch부터 학습했기 때문에 학습량 차원에서는 공정한 비교가 아닙니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/15-result-tl.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 다양한 데이터셋에 대해 transfer learning으로 학습했을 때, supervised learning에 준하거나 그 이상의 결과를 보여주었습니다.&lt;/p&gt;

&lt;h1 id=&quot;simclr-v2&quot;&gt;&lt;em&gt;SimCLR v2&lt;/em&gt;&lt;/h1&gt;

&lt;p&gt;앞서 설명한 SimCLR은 각종 평가 지표에서 SOTA의 성능을 보여주었습니다. SimCLR v2에서는 다양한 실험을 통해 기존 SimCLR의 성능을 개선하는 한편, few-labeled 데이터셋을 활용하여 SimCLR을 fine-tuning하고, 작거나 같은 크기의 모델로의 distillation 과정을 통해 모델의 효율성을 극대화하여 semi-supervised learning에서도 SOTA의 성능을 달성했습니다. 이는 NLP 분야에서 좋은 성능을 발휘한 BERT의 학습 패러다임과 나날이 발전하고 있는 student-teacher 기반의 semi-supervised learning 기법을 통합한 형태로, computer vision 분야에서는 어떤 형태로 연구되었는지 설명드리겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/17-simclrv2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;전반적인 framework의 구조는 위와 같습니다. SimCLR 기반의 unsupervised learning 방법으로 visual representation을 학습한 후에, 적은 labeled 데이터를 이용하여 이를 fine-tuning합니다. 이 때 unsupervised learning 과정은 최종 task와는 전혀 무관한 contrastive prediction task를 이용하여 학습을 진행했기 때문에 본문에서는 task-agnostic이라는 단어를 이용하여 표현하였습니다. 이후 fine-tuning된 모델은 unlabeled 데이터와 labeled 데이터를 모두 이용한 distillation 과정을 통해 성능 및 효율성 차원에서 고도화됩니다.&lt;/p&gt;

&lt;h2 id=&quot;self-supervised-pretraining-with-simclr-v2&quot;&gt;Self-supervised Pretraining with SimCLR v2&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/18-model-size.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SimCLR v2는 세 가지 측면에서 개선되었습니다. 우선 기존에 ResNet-50을 4배 키운 모델을 이용했었는데, SimCLR v2에서는 ResNet-152를 3배 키우고 selective kernel을 더해 channel별로 attention을 가해주었습니다. 이는 기존과 비교했을 때 2배 정도 많은 parameter를 이용하지만, 1% labeled sample로 fine-tuning 했을 때 29%의 놀라운 top-1 accuracy 성능 향상을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/20-projection-head-size.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 SimCLR v2는 projection head를 구성하는 linear layer 개수를 2개에서 3개로 늘렸고, 학습 후에 모든 projection head를 버리는 것이 아니라 첫 번째 linear layer까지 encoder에 포함하였습니다. 이는 결국 기존 base encoder의 구조에 linear layer 하나를 추가한 것과 같은 구조인데, 앞선 실험과 마찬가지로 1% sample로 fine-tuning을 했을 때 14%의 top-1 accuracy 성능 향상을 보여주었습니다. 위의 그림은 projection head의 layer를 늘렸을 때와 projection head를 fine-tuning 과정에 포함했을 때 결과를 나타내고 있는데요. Projection head가 많을 수록 few-labeled 데이터에서 좋은 성능을 보이고, 그 중 첫번째 head를 fine-tuning에 포함할 때 성능이 가장 크게 향상되는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;마지막으로 SimCLR v2는 MoCo에서 영감을 받아 negative example을 최대한 늘리기 위한 memory network를 추가하였습니다. 하지만 이는 1% 정도의 적은 성능 향상을 보여주었는데, 논문에서는 기존 SimCLR이 4096개 이상의 batch size로 충분히 많은 negative sample을 제공하기 때문이라고 설명하고 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;distillation-via-unlabeled-samples&quot;&gt;Distillation via Unlabeled Samples&lt;/h2&gt;

&lt;p&gt;SimCLR v2는 projection head의 일부를 포함한 fine-tuning을 거친 후에, distillation 과정을 통해 성능 향상을 달성하였습니다. Student-Teacher 기반의 distillation 방법은 사전 학습된 teacher network(fine-tuning된 SimCLR v2)를 이용해 unlabeled 데이터에 대한 hidden layer output vector를 생성하고, 이를 기반으로 distillation loss를 활용하여 student network를 학습시키는 방법입니다.&lt;/p&gt;

&lt;p&gt;만약 Student network의 크기가 teacher network의 크기보다 작은 경우에는, teacher network와 유사한 성능을 더 작은 모델로 달성할 수 있기 때문에 모델의 효율성 측면에서 개선의 여지가 있으며, teacher network와 같은 student network를 쓰는 경우에는 self-distillation을 통한 성능 개선이 가능합니다. 또한 적은 양의 labeled 데이터가 있는 경우에 이를 활용하여 distillation의 성능 향상폭을 극대화할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/21-distillation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림은 1% 또는 10% 데이터로 fine-tuning한 모델과, 이후에 distillation 과정까지 진행한 모델, 그리고 모든 데이터로 supervised-learning을 진행한 모델의 성능을 비교하였습니다. 적은 labeled data의 경우에 distillation 과정을 통해 성능 향상이 발생하며, supervised learning에 거의 준하는 성능을 보이는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;discussion-and-result&quot;&gt;Discussion and Result&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/19-model-size2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;논문에서는 SimCLR의 성능을 개선하고 semi-supervised learning 분야에서 이를 활용하기 위해 수많은 실험을 진행하였습니다. 이 실험들은 공통적으로 모델의 크기를 키우면 contrastive learning이나 fine-tuning 결과가 개선된다는 것을 보여줍니다. 사실 모델의 크기를 키우면, 모든 데이터의 특징을 외울 수 있기 때문에 generalization이 떨어지고 성능 저하가 발생하기 쉬워보입니다. 논문에서도 모델을 키울수록 성능이 향상되는 실험 결과들에 대한 해석을 찾지 못했으며, 추후에 연구되길 바란다고 이야기하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210410-SimCLR/22-simclr-v2-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 distillation 과정을 거친 SimCLR v2 모델은 이전의 모든 self-supervised learning과 semi-supervised learning 기법들을 능가하는 SOTA의 성능을 보이고 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;SimCLR은 contrastive learning 기반의 학습을 통해 supervised learning에 준하는 성능의 unsupervised learning 학습 결과를 보여주었습니다. 물론 학습을 안정성을 위해 아주 큰 batch size를 이용해야 하고, 일반적인 연구실의 GPU 환경에서는 논문에서 사용한 4096개 정도의 batch size를 감당할 수 없기에, 구글이기에 할 수 있었던 연구였구나 하는 생각도 듭니다.&lt;/p&gt;

&lt;p&gt;이어서 나온 SimCLR v2는 pre-training and fine-tuning이라는 패러다임에 맞게 학습을 진행했고, distillation을 통해 성능을 고도화했습니다. 다양한 실험을 통해 self- 그리고 semi-supervised learning에 대한 통찰을 하는 논문이라고 생각합니다.&lt;/p&gt;

&lt;p&gt;분명한 것은 NLP에서 BERT 및 GPT3 등이 큰 성공을 거두고 있는 지금, 구글의 SimCLR은 computer vision에서의 unsupervised learning 연구에 큰 기여를 했고, 앞으로 어떤 모델이 나올지 기대해보며 이번 리뷰글을 마치겠습니다. 읽어주셔서 감사합니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.05709&quot;&gt;https://arxiv.org/abs/2002.05709&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.10029&quot;&gt;https://arxiv.org/abs/2006.10029&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/google-research/simclr&quot;&gt;https://github.com/google-research/simclr&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="CV" /><category term="CV" /><summary type="html">원문 : Chen, Ting, et al. “A simple framework for contrastive learning of visual representations.” International conference on machine learning. PMLR, 2020. &amp;amp; Chen, Ting, et al. “Big self-supervised models are strong semi-supervised learners.” arXiv preprint arXiv:2006.10029 (2020).</summary></entry><entry><title type="html">Point Transformer 리뷰</title><link href="https://rauleun.github.io/Point-Transformer" rel="alternate" type="text/html" title="Point Transformer 리뷰" /><published>2021-03-02T09:00:00+09:00</published><updated>2021-03-02T09:00:00+09:00</updated><id>https://rauleun.github.io/Point%20Transformer</id><content type="html" xml:base="https://rauleun.github.io/Point-Transformer">&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/2012.09164&quot;&gt;Zhao, Hengshuang, et al. “Point transformer.” arXiv preprint arXiv:2012.09164 (2020).&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 2020년 발표된 &lt;strong&gt;&lt;em&gt;Point Transformer&lt;/em&gt;&lt;/strong&gt; 논문에 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;Transformer 구조는 Natural language processing(NLP) 분야에서 처음 소개된 이후로, NLP 뿐만 아니라 object classification 및 detection 등 다양한 task에 적용되어 뛰어난 성능을 보여주고 있습니다.&lt;/p&gt;

&lt;p&gt;Point Transformer는 point cloud classification 및 segmentation task에 transformer 구조를 적용한 논문인데, 구체적으로는 self-attention 연산을 이용해서 feature를 추출하였습니다. Transformer의 self-attention mechanism은 permutation-invariant한 특성을 가지고 있기 때문에 point cloud 형태의 데이터에 바로 적용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;논문에서는 이런 self-attention layer를 이용해서 U-net 형태의 구조를 가진 네트워크를 형성하였습니다. 그럼 구체적으로 Point Transformer가 어떤 구조로 구성되어 있는지 설명드리겠습니다. (Transformer 또는 self-attention에 대한 이해가 부족하신 분들은 &lt;a href=&quot;https://rauleun.github.io/attention-is-all-you-need&quot;&gt;Attention is all you need&lt;/a&gt; 리뷰를 보고 오시면 좋습니다.)&lt;/p&gt;

&lt;h2 id=&quot;point-transformer-layer&quot;&gt;Point Transformer Layer&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/1-point-transformer-layer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Point Transformer network에서는 point transformer layer를 정의하고, 이를 통해 점들 간의 관계를 고려한 feature vector를 multi-scale로 추출해주었습니다. 이는 vector-based self-attention 연산에 기반을 두고 있는데, &lt;em&gt;scalar-based&lt;/em&gt; 와 &lt;em&gt;vector-based self-attention&lt;/em&gt; 은 attention 값의 형태가 scalar인지 vector인지에 따라 구별됩니다. Vector-based self-attention의 경우에는 attention vector가 feature vector와 같은 크기로 정해져서, elementwise 곱을 통해서 최종 output vector를 얻게 됩니다.&lt;/p&gt;

&lt;p&gt;이러한 self-attention 연산은 기본적으로 &lt;em&gt;set operator&lt;/em&gt; 이기 때문에, set 형태의 구조를 가진 point cloud 연산에 특화되어 있습니다. 논문에서는 이를 활용하여 위와 같은 구조의 point transformer layer를 구성하였습니다. 구조는 생각보다 간단합니다. 한 점과 그 점의 kNN에 해당하는 점들을 input으로 하고, 점들 간 feature vector의 차이와 attention vector를 곱해서 output vector를 추출합니다.&lt;/p&gt;

&lt;p&gt;기본적으로 point transformer layer에서 얻은 output vector는, input point cloud의 점의 개수와 같은 수의 점들로 구성되어 있으며, vector의 차원은 중간에 존재하는 MLP 또는 linear layer의 input/output size에 따라 달라질 수 있습니다. 따라서 여러 layer를 이어붙일 수도 있고 up/down-sampling layer를 이용해서 U-Net 형태의 구조를 가진 network를 구성할 수도 있습니다.&lt;/p&gt;

&lt;p&gt;또한 특이한 점은 기존의 transformer처럼 global하게 모든 점을 input으로 넣는 것이 아니라, 각 점에 대해 인접한 k개의 점만 선택해서 input으로 이용한다는 점입니다. 아마 sub-sampling을 하지 않고 모든 점들을 넣게 되면 input의 길이가 너무 길어져서 attention을 제대로 학습할 수 없고, 한 점에 대한 계산량도 많이지기 때문이 아닐까 생각됩니다. 논문에서는 연관되지 않는 점들에 대한 attention이 noise로 작용해서 성능을 떨어트렸다고 이야기하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/2-point-transformer-block.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 point transformer layer의 위/아래에 vector의 차원 조정을 위한 linear layer와 residual connection을 더해서 위의 그림과 같은 구조의 point transformer block을 형성했습니다. 이 block은 feature vector들의 정보를 통합하는 역할을 하며 추후에 설명드릴 point transformer network의 중요한 구성 요소로 이용됩니다.&lt;/p&gt;

&lt;h2 id=&quot;positional-encoding&quot;&gt;Positional Encoding&lt;/h2&gt;

&lt;p&gt;기존 transformer에서는 sequence 내 요소들의 순서를 나타내기 위해 각 embedding vector에 positional encoding vector를 더해주었습니다. Point transformer에서도 마찬가지로 positional encoding vector를 이용했는데, 각 점들의 xyz 좌표값이 점들 간의 위치 관계를 담고 있기 때문에 이를 활용하여 positional encoding vector를 생성하였습니다.&lt;/p&gt;

&lt;p&gt;Positional encoding vector는 2개의 linear layer와 하나의 ReLU로 구성된 MLP를 학습시켜 얻었습니다(learnable positional embedding). 생성된 positional encoding vector는 self-attention 연산 중간에(attention generation 및 feature transformation) 더해줌으로써 점들 간의 위치 관계나 구조가 layer의 output에 반영될 수 있게 구현되었습니다.&lt;/p&gt;

&lt;h2 id=&quot;point-transfomer-network&quot;&gt;Point Transfomer Network&lt;/h2&gt;

&lt;p&gt;Point transformer network는 point cloud classification 및 segmentation task를 수행하기 위해 point transformer block을 활용하여 구성한 network입니다. Network는 point transformer block 및 pooling layer 등을 활용하여 구성되었고, continuous convolution이나 graph convolution 등 기존 연구들에서 feature extraction을 위해 사용했던 연산은 일절 활용되지 않았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/4-point-transformer-network.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;전체적인 구조는 위의 그림과 같습니다. Image segmentation 분야에서 주로 사용되는 U-Net 구조와 유사한데, down-sampling과 up-sampling 과정을 통해 5개 scale의 point set에서 정보를 추출하였습니다. 또한 같은 scale의 point set들은 residual connection으로 연결해주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/3-transition-block.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림에서 왼쪽에 보이는 down-sampling layer는 서로 가장 거리가 먼 N개의 점들을 선택해주는 farthest point sampling 알고리즘을 이용했고, 해당 점의 feature vector는 주변 점들의 feature vector들에 대해 local하게 max-pooling 연산을 수행해서 얻었습니다. 오른쪽의 up-sampling layer는 segmentation task의 경우에 점들 별로 feature vector를 얻어야 하기 때문에 점들의 개수를 다시 늘려주기 위해 필요합니다. 이는 더 많은 점들로 구성된 point set에 대한 interpolation과 skip-connection layer로 구성되었습니다.&lt;/p&gt;

&lt;p&gt;Network의 마지막은 linear layer들로 구성된 MLP를 통해 합쳐진 feature vector들의 차원을 적절하게 조정해주었습니다. 특히 segmentation model에서는 각 점들에 대한 embedding vector 별로 classification logit을 추출해서 해당 점의 class 정보를 얻을 수 있게 구성되었습니다.&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;Point Transformer Network의 classification / segmentation version의 성능을 측정하기 위해 다양한 실험을 진행했습니다. ModelNet40, ShapeNet, S3DIS 등의 대표적인 dataset을 이용하여 성능을 평가했습니다. 결과는 대부분 SOTA!를 달성했습니다. 다만 공식적으로 code 및 model이 공개되지 않았고, 때문에 정확한 reproduction 및 평가 결과가 확인되지 않는 것이 아쉬웠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Semantic Segmentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/5-s3dis-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;S3DIS dataset을 이용해서 실내 환경에 대한 semantic segmentation 성능을 평가하였습니다. Area 5를 제외한 나머지로 모델을 학습하고, Area 5로 모델을 평가하였습니다. mIOU 및 OA가 70.4%, 90.8%를 기록하며 SOTA의 성능을 보여주었습니다. (기존에 KPConv에서 달성한 SOTA 성능을 뛰어넘었습니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/8-s3dis-vis-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림은 결과를 시각화한 것인데, 의자의 다리 등 detail한 부분까지도 잘 classification 하는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Shape Classification&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/6-modelnet-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ModelNet40 dataset을 이용해서 shape classification 성능을 평가하였습니다. 기존 dataset에서 점들을 2048개 정도로 sub-sampling하여 input으로 활용하였습니다. 마찬가지로 graph convolution 기반의 방법들이나, continuous convolution 기반의 KPConv를 제치고 SOTA의 성능을 달성하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/9-modelnet-vis-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Point transformer network를 통해서 나온 최종 embedding vector의 타당성을 보이기 위해, 임의의 물체의 embedding vector와 거리가 가까운 embedding vector들의 원래 모습을 검색해보았습니다. 위의 그림에서 알 수 있듯 차에 대한 embedding들이 서로 가깝고, 책상에 대학 embedding이 가깝게 잘 mapping되는 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;h2 id=&quot;ablation-studies&quot;&gt;Ablation studies&lt;/h2&gt;

&lt;p&gt;그 외에 몇 가지 간단한 ablation study를 진행했습니다. 우선 주변 몇 개의 점들까지 neighboring point로 볼 것인가에 대한 &lt;em&gt;k&lt;/em&gt; 값을 바꿔가면서 결과를 비교했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/10-ablation-k.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;k&lt;/em&gt; 값을 16으로 두었을 때 가장 성능이 좋았습니다. &lt;em&gt;k&lt;/em&gt; 를 4나 8 정도로 두면, 주변의 구조나 관계에 대한 정보가 부족해서 학습 성능이 충분히 나오지 않는 것으로 보였습니다. 반면에 &lt;em&gt;k&lt;/em&gt; 를 32나 64 정도로 크게 잡으면, 너무 많은 점들이 들어오게 되어 연관성이 없는 점들이 noise로 작용하고, 결국 정확도를 떨어트렸습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210302-PointTransformer/11-ablation-attention.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 self-attention 연산의 종류에 대해서 실험했습니다. 논문에서는 vector-based attention을 기준으로, 아예 attention을 사용하지 않았을 때(MLP, MLP + pooling)와 scalar-based attention을 사용했을 때의 결과를 비교했습니다. Vector-based self-attention을 이용했을 때 전반적인 성능이 가장 잘 나왔는데, feature vector의 각 channel이 이론적으로는 서로 independent하기 때문에 각각에 맞는 attention weight를 가해줄 수 있을 때 feature 변환이 가장 효율적으로 이뤄지는 것으로 설명했습니다.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Point transformer는 point cloud를 transformer 구조를 이용해서 다룬 초창기 논문인데도 graph convolution, continuous convolution 기반의 논문들을 제치고 SOTA의 성능을 달성하였습니다. Point cloud가 set 형태의 data이기 때문에, 그에 맞는 set operator를 이용했을 때 성능이 월등하게 잘 나오지 않았나 싶습니다. Transformer를 적용한 초창기 연구이기 때문에 추후에 더 뛰어난 model들이 많이 발표되지 않을까 생각됩니다. 개인적인 바람으로는 official code를 공개해주었으면 좋겠습니다.&lt;/p&gt;

&lt;p&gt;그럼 이만 마무리하겠습니다. 궁금하거나 잘못된 점이 있다면 댓글 부탁드리겠습니다. 읽어주셔서 감사합니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2012.09164&quot;&gt;https://arxiv.org/abs/2012.09164&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="3d" /><category term="3d" /><summary type="html">원문 : Zhao, Hengshuang, et al. “Point transformer.” arXiv preprint arXiv:2012.09164 (2020).</summary></entry><entry><title type="html">KPConv - Flexible and Deformable Convolution for Point Clouds 리뷰</title><link href="https://rauleun.github.io/KPConv" rel="alternate" type="text/html" title="KPConv - Flexible and Deformable Convolution for Point Clouds 리뷰" /><published>2021-02-07T09:00:00+09:00</published><updated>2021-02-07T09:00:00+09:00</updated><id>https://rauleun.github.io/KPConv</id><content type="html" xml:base="https://rauleun.github.io/KPConv">&lt;p&gt;원문 : &lt;a href=&quot;https://openaccess.thecvf.com/content_ICCV_2019/html/Thomas_KPConv_Flexible_and_Deformable_Convolution_for_Point_Clouds_ICCV_2019_paper.html&quot;&gt;Thomas, Hugues, et al. “Kpconv: Flexible and deformable convolution for point clouds.” Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 2019년 ICCV에서 소개된 &lt;strong&gt;&lt;em&gt;Kpconv: Flexible and deformable convolution for point clouds&lt;/em&gt;&lt;/strong&gt; 논문에 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;Kernel point convolution(KPConv)는 3D point cloud 형태의 데이터를 처리하기 위한 여러가지 방법들 중 graph나 3D voxel 등의 형태로 변환하지 않고 point cloud에 직접 convolution을 적용하는 류의 방법입니다. 하나의 convolution kernel은 여러 개의 kernel point들로 구성이 되어있고 각 kernel point마다 연속적인 값을 가지는 kernel weight을 배치하여 주변 점들에 대한 convolution 연산을 수행했습니다. 이 때 kernel point의 개수와 위치를 유동적으로 설정해줌으로써 network capacity를 조절할 수 있고, kernel의 형태를 point cloud의 기하학적 형태에 최적화하여 설정해줄 수 있습니다. KPConv는 3D point cloud classification이나 segmentation 등의 task에서 SOTA의 성능을 기록하였습니다. 그럼 지금부터 KPConv를 파헤쳐보겠습니다!&lt;/p&gt;

&lt;h2 id=&quot;kernel-point-convolution&quot;&gt;Kernel point convolution&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/1-kpconv.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;한 점에 대한 kernel point convolution 연산은 일정한 반지름 &lt;em&gt;r&lt;/em&gt; 내부에 있는 주변 점들을 대상으로 합니다. 일반적으로 이웃한 점을 정의할 때 이용하는 kNN과 달리, 반지름을 정의하여 내부에 있는 모든 점들을 이웃한 점으로 정의하게 되면, 점 밀도의 변화에 대해 robust하며 해당 점들에 대한 일정 크기의 kernel을 정의하기가 훨씬 더 수월해집니다. 이렇게 구 형태의 kernel 유효 범위를 정의하게 되면, 범위 내에 특정 개수의 kernel point들을 배치하여 kernel point 별로 kernel weight을 할당합니다. Kernel weight은 각 kernel point에 대해 correlation function과 상수 (&lt;em&gt;W&lt;/em&gt;) 의 곱으로 정의하며, correlation function은 kernel point와 점의 거리가 가까울수록 커지는 linear function을 이용합니다. 예를 들면, 위의 그림에서 각 kernel point에 대해 kernel point와의 거리가 멀어질수록 filter value의 절대값이 작아지는 것을 볼 수 있습니다. Filter value의 부호나 크기는 학습에 의해 정해지는 kernel의 상수값 &lt;em&gt;W&lt;/em&gt;에 따라 달라지고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/2-convolution.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 여러 개의 kernel point들로 구성된 각 kernel들을 point cloud의 모든 점에 대입하여 convolution 연산을 해줍니다. Kernel의 개수에 따라서 output feature의 차원이 결정됩니다. 또한 모든 kernel 내 filter value들은 학습에 의해 정해집니다. 이는 위의 그림처럼 image에 적용하는 2D convolution과 정확히 같은 형태입니다. 두 경우 모두 각 Kernel에 대해 convolution 연산(elementwise 곱의 합)을 적용하고, 이 결과를 kernel 별로 쌓아 새로운 feature vector를 형성합니다.&lt;/p&gt;

&lt;p&gt;논문에서는 사전에 정의되어 고정된 kernel point 위치를 사용하는 rigid KPConv와 주변 점들의 분포에 따라 유동적으로 변화하는 kernel point 위치를 사용하는 deformable KPConv의 두 가지 연산을 정의하는데, rigid KPConv의 경우 classification이나 part segmentation 등 간단한 task에서, deformable KPConv의 경우 semantic segmentation과 같은 어려운 task에서 좋은 성능을 보여주었다고 합니다. 그럼 각각에 대해서 설명해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;rigid-kernel-point-convolution&quot;&gt;Rigid kernel point convolution&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/12-rigid-kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Rigid KPConv는 정해진 몇 개의 kernel point에 대해 kernel weight을 배치하여 convolution 연산을 수행합니다. 가장 효율적으로 convolution 연산을 수행하기 위해 repulsive potential과 attractive potential의 합을 최소화하는 최적화 방정식을 정의하였습니다. 이 때 효율적인 convolution 연산이라는 것은, 각 kernel point들의 correlation range가 kernel의 유효 범위를 모두 포함하며 kernel point 간에 겹치는 범위는 최소화하는 것을 의미합니다. Kernel point의 개수를 &lt;em&gt;K&lt;/em&gt; 라고 할 때, 최적화 방정식의 해는 &lt;em&gt;K&lt;/em&gt; 값에 따른 가장 효율적인 kernel point들의 배치입니다. 아래 그림에서는 몇 개의 &lt;em&gt;K&lt;/em&gt; 값에 대한 kernel point의 배치를 보여주고 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;deformable-kernel-point-convolution&quot;&gt;Deformable kernel point convolution&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rigid kernel point convolution을 정의하면 효율적으로 point cloud가 존재하는 공간의 정보를 모을 수 있습니다. 여기에서 좀 더 나아가서 kernel point들의 위치를 학습을 통해 결정할 수 있다면, 주변 점들의 분포를 가장 이상적으로 표현하도록 kernel point들이 배치될 것이므로, 고정되어 있을 때보다 convolution 연산이 가지는 정보의 capacity가 훨씬 커질것입니다. 또한 3D point cloud 형식의 특성상 점들의 분포가 규칙적이지 않으므로, deformable convolution을 적용하게 되면 점들이 존재하지 않는 공간에 대한 무의미한 kernel point 배치를 최소화할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/3-deformable.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이를 위해 &lt;em&gt;deformable version&lt;/em&gt; 의 network에서는, rigid KPConv 연산을 통해 K개 점에 대한 shift vector를 추출해주는 layer를 추가하였습니다. (Shift vector는 xyz 좌표를 포함하므로 총 3K개의 좌표를 추출합니다.) 이렇게 얻어진 벡터를 local shift로 정의하고 이에 따라 kernel point의 위치를 옮겨줍니다. Network 학습 과정에서는 local shift를 생성하는 rigid KPConv layer와 이를 통해 output feature를 생성하는 deformable KPConv layer를 동시에 학습하였습니다.&lt;/p&gt;

&lt;p&gt;하지만 이렇게 학습을 진행하게 되면 input point와 접점이 없는 kernel point들은 back propagation 과정에서 gradient 값을 잃게 되고, 결국 network는 kernel point를 잃어버리게 됩니다. 이는 point 들의 분포가 일정하지 않은 3D point cloud의 특성 때문인데, 이를 해결하기 위해 가장 가까운 input neighboring point와의 거리를 제한하는 regularization loss와 kernel point 간의 범위 중복을 최소화하기 위한 repulsive loss를 추가하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/13-deformable-kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;두 loss들을 통해 network는 위의 그림처럼 input point cloud의 geometry와 맞는 형태의 local shift를 추출하였습니다. Regularization loss가 없을 때에는 kernel point들이 input point cloud와 멀리 위치하는 경우들이 존재하였습니다. 이러한 경우에는 convolution 연산이 주변 점들의 정보를 잘 통합하지 못하여 특징 벡터의 표현력이 떨어질 수 밖에 없게됩니다. 하지만 regularization loss를 통해 input point들이 존재하는 영역들에 kernel point를 배치한다면, convolution을 통해서 얻은 특징 벡터가 주변 구조를 더 잘 표현하게 됩니다.&lt;/p&gt;

&lt;p&gt;위에서 소개한 두 가지 convolution 연산은 block 형태로 통합되어 전체 network를 구성하는 데에 사용하였습니다. 두 convolution block은 모두 skip-copnnection, batch normalization, leaky ReLU 등을 이용하여 학습의 안정성과 성능을 도모하였습니다. 아래에 구조를 담은 그림을 참고하면, deformable block에서는 KPConv 연산을 통해 3K 크기의 local shift vector를 추출하는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/10-network-architecture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kernel-point-network&quot;&gt;Kernel Point Network&lt;/h2&gt;

&lt;p&gt;논문에서는 KPConv 연산을 활용하여 network를 구축하였습니다. Network는 U-Net과 유사하게 pooling layer과 upsampling layer를 이용하여 multi-scale의 feature vector를 추출하였습니다. 이 때 pooling을 하면서 점들을 sub-sampling 하는 과정이 필요한데, input point의 density에 independent한 grid subsampling 방법을 이용하였습니다. 이는 점들을 voxel 형태의 grid에 놓은 뒤, 각 grid의 무게중심에 해당하는 점들만을 sampling하는 방법입니다. Pooling 과정은 앞서 설정한 grid의 cell size를 2배씩 키워서 output point의 개수를 줄여나간 뒤에, KPConv를 통해 각 cell 내부의 점들에 대한 feature vector를 통합해주었습니다. 이를 strided KP-Conv라고 부르기도 하였습니다.&lt;/p&gt;

&lt;p&gt;Network parameter는 cross validation을 통해서 결정했습니다. Kernel point의 개수는 15, convolution radius와 kernel point radius는 각각 단위길이의 2.5, 1.5배를 이용하였습니다. Subsampling cell size는 pooling layer마다 2배씩 증가하게끔 설정해주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/11-network-architecture-fig.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Network는 classification 및 segmentation에 대한 각각의 task 별로 하나씩 구성하였습니다. 위의 그림에서 Classification을 위한 network는 KP-CNN, segmentation을 위한 network는 KP-FCNN이라고 부릅니다. KP-FCNN은 KP-CNN의 encoder 부분을 공유하지만, segmentation task의 특징 상 점들 별로 하나 씩의 class output을 도출해야 하기 때문에, nearest upsampling 과정을 통해 점들의 개수를 맞춰준 후에 point-wise feature를 추출했습니다. 반면에 KP-CNN은 encoder를 통해 얻은 feature vector로부터 fully-connected layer를 활용하여 곧바로 class 정보를 추출하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;3D Shape Classification and Segmentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/4-modelnet-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;모델은 가장 일반적인 3D classification dataset인 ModelNet40과 part segmentation dataset인 Shapenet을 이용하여 성능을 평가하였습니다. Grid subsampling을 이용했기에 점들의 개수는 data마다 달랐지만, KPConv 과정에서 variable batch size에 대한 normalization 처리를 해주었기 때문에 아무런 문제가 되지 않았습니다. 또한 point cloud의 크기를 바꾸거나, 좌우 반전 및 점들을 일부 제거하는 등의 augmentation 과정을 통해 dataset의 개수를 늘려주었습니다. KPConv를 이용한 두 모델은 각 dataset에 대해 SOTA의 성능을 달성하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;3D Scene Segmentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/5-segment-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3D scene segmentation task에서는 indoor, outdoor scene에 대한 Scannet, S3DIS, Semantic3D 등의 dataset을 이용하여 성능을 평가하였습니다. 보통 3D scene dataset의 크기가 굉장히 크기 때문에, 부분적으로 구 형태의 subcloud를 분리하고 그에 대해서만 segmentation 작업을 수행했습니다. Network에 input으로 들어가는 구는 2m 또는 4m의 반지름을 가지게끔 설정해주었습니다. Rigid convolution과 deformable convolution을 이용한 network는 각 task에서 모두 뛰어난 성공을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/6-segment-result-fig.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;특히 deformable convolution을 활용한 network는 더 큰 capacity를 가지고 있기 때문에 dataset이 더 크고 다양한 data로 구성되어있을 때 더 좋은 성능을 보여주었습니다. 아래의 그림처럼 kernel point의 개수가 줄어들어도, deformable convolution이 충분한 표현력을 가지고 있기 때문에 성능이 크게 줄어들지 않는 것을 확인할 수 있었습니다. 또한 deformable convolution은 class의 종류가 훨씬 다양한 indoor segmentation에서 좋은 성능을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210207-KPConv/7-kernel-point-iou.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Kernel point convolution은 point cloud에 직접 convolution을 적용하는 방법으로 classification 및 segmentation task에 대한 SOTA의 성능을 보여주었습니다. 논문에서는 kernel point의 위치가 고정된 rigid KPConv와 객체의 형태에 따라 변화하는 deformable KPConv를 제안하여 dataset의 크기나 다양성에 맞게 convolution block을 선택할 수 있게 제안하였습니다. 또한 연산 방법의 성능을 검증하기 위해 다양한 실험을 진행하였고, github에 코드도 잘 정리되어 있으니 좋은 성능의 3D classification 및 segmentation model이 필요하다면 꼭 알아야 할 연구라고 생각됩니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://openaccess.thecvf.com/content_ICCV_2019/papers/Thomas_KPConv_Flexible_and_Deformable_Convolution_for_Point_Clouds_ICCV_2019_paper.pdf&quot;&gt;https://openaccess.thecvf.com/content_ICCV_2019/papers/Thomas_KPConv_Flexible_and_Deformable_Convolution_for_Point_Clouds_ICCV_2019_paper.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/HuguesTHOMAS/KPConv&quot;&gt;https://github.com/HuguesTHOMAS/KPConv&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="3d" /><category term="3d" /><summary type="html">원문 : Thomas, Hugues, et al. “Kpconv: Flexible and deformable convolution for point clouds.” Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.</summary></entry><entry><title type="html">Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs 리뷰</title><link href="https://rauleun.github.io/Superpoint-Graphs" rel="alternate" type="text/html" title="Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs 리뷰" /><published>2021-01-29T09:00:00+09:00</published><updated>2021-01-29T09:00:00+09:00</updated><id>https://rauleun.github.io/Superpoint-Graphs</id><content type="html" xml:base="https://rauleun.github.io/Superpoint-Graphs">&lt;p&gt;원문 : &lt;a href=&quot;https://openaccess.thecvf.com/content_cvpr_2018/html/Landrieu_Large-Scale_Point_Cloud_CVPR_2018_paper.html&quot;&gt;Landrieu, Loic, and Martin Simonovsky. “Large-scale point cloud semantic segmentation with superpoint graphs.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 2018년 CVPR에서 소개된 &lt;strong&gt;&lt;em&gt;Large-scale point cloud semantic segmentation with superpoint graphs&lt;/em&gt;&lt;/strong&gt; 논문에 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210129-superpoint-graphs/1-spg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;기존에 진행된 많은 AI 기반의 point cloud 연구는 좋은 성능을 보여주었지만, input size의 한계 때문에 적은 수의 점들로 구성된 point cloud에 대해서만 적용할 수 있었습니다. Neural network는 몇 백만개 이상의 점들로 구성된 LiDAR scan을 직접 다루기 어려웠고, down-sampling 하는 등의 후처리를 거쳐서 network의 input으로 이용했습니다. 하지만 이는 point cloud의 장점인 물체에 대한 정교한 표현력을 떨어트릴 수밖에 없었습니다. 오늘 소개드릴 연구는 기존의 연구와는 달리 몇 백만개 단위의 점들로 구성된 point cloud를 대상으로 semantic segmentation을 수행하였습니다. 논문에서는 유사한 구조의 점들을 superpoint라는 하나의 점으로 모아서 새로운 그래프(superpoint graph)를 구성했습니다. Superpoint graph(SPG)는 많은 점들로 구성되어 물체 간의 의미론적 관계에 대한 풍부한 정보를 담고 있기 때문에 semantic segmentation 성능을 크게 끌어올릴 수 있었습니다.&lt;/p&gt;

&lt;p&gt;수학적인 내용이 많아 어려웠지만, 최대한 잘 정리해보겠습니다 :)&lt;/p&gt;

&lt;h2 id=&quot;superpoint-graph-spg&quot;&gt;Superpoint Graph (SPG)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/210129-superpoint-graphs/2-spg-process.png&quot; alt=&quot;&quot; /&gt;
SPG는 point cloud로부터 크게 세 단계를 거쳐서 생성됩니다. 우선, 전체 point cloud에서 기하학적으로 비슷한 구조를 가진 점들을 묶어서 작은 여러 개의 point cloud로 분리합니다. 이후, 분리된 각각의 point cloud를 하나의 점으로 변환하는데, 이를 논문에서는 superpoint라고 정의합니다. 이 때 분리된 point cloud 내에 속한 점들의 feature vector를 통합해서 각 superpoint의 embedding vector를 추출합니다. 마지막으로 superpoint 간의 연결 관계를 파악해서 edge를 연결하고, 이를 graph convolution network에 넣어서 segmentation task를 수행합니다. 그럼 각각의 부분에 대해서 자세히 설명하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Geometric Partitioning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Superpoint graph를 구성하기 위해서는 우선 많은 수의 점들로 구성된 point cloud를 작은 점들의 단위로 분리해주어야 합니다. 이 때 단순하고 비슷한 기하학적 모양을 가진 점들을 묶어줌으로써, 점들이 전반적으로 균일한 의미론적 특징을 가지고 실제로도 같은 class에 해당하게끔 설정해주었습니다. 또한 많은 수의 점들이 partitioning 과정을 거쳐야 하기 때문에 계산량 측면에서 효율적인 방법을 이용해주어야 합니다. 논문에서는 global energy model을 통해서 점들을 분리해주었습니다.&lt;/p&gt;

&lt;p&gt;Global enerygy model은 각 점마다 주변 점들의 모양에 대한 특징을 담은 geometric vector를 계산하고, geometric vector가 비슷한 점들 끼리 연결해주는 partitioning 방법입니다. 논문에서는 각 점과 주변 점들에 대한 선형성(linearity), 평면성(planarity), 분산성(scattering), 수직성(verticality)와 높이를 geometric vector로 이용했습니다. 이후 점들의 geometric vector들에 대한 최적화 문제를 푸는 방식으로 connected components를 찾아주었습니다. Point cloud의 크기가 커질 경우에 geometric vector가 nonconvex 하거나 noncontinuous 할 수 있기 때문에, 이러한 경우 graph cut 알고리즘의 하나인 persuit cut을 이용해서 graph를 여러 개로 나눠 크기를 줄여주었습니다. (Graph cut 알고리즘은 분리된 점들 간의 edge distance가 가장 멀게끔 graph를 두 개로 나누는 방법입니다.)&lt;/p&gt;

&lt;p&gt;이렇게 partitioning을 통해서 connected components &lt;em&gt;S = {S1, S2, …, Sk}&lt;/em&gt; 를 얻을 수 있는데, 각 component들은 기하학적으로 간단한 구조를 가지며 component 내의 점들은 같은 구조를 가지게 됩니다. 앞으로는 이를 superpoint라고 부르고, 이를 통해 graph를 형성해서 segmentation을 수행할 것입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Superpoint Graph Construction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 각 superpoint를 node로 하는 하나의 graph를 형성할 것입니다. 일단 superpoint를 형성하기 전, 전체 input point cloud에 대해 인접한 점들을 연결하는 Voronoi adjacency graph를 형성합니다. Superpoint 간의 연결관계는 superpoint 내에 속한 점들이 Voronoi adjacency graph 상에서 연결되었는지에 따라 결정합니다. 예를 들면, &lt;em&gt;S&lt;/em&gt; 와 &lt;em&gt;T&lt;/em&gt; 라는 superpoint가 있고 내부에 각각 &lt;em&gt;s1&lt;/em&gt; 과 &lt;em&gt;t1&lt;/em&gt; 이라는 점이 소속되어 있다고 하면, &lt;em&gt;s1&lt;/em&gt; 과 &lt;em&gt;t1&lt;/em&gt; 이 연결되었다면 &lt;em&gt;S&lt;/em&gt; 와 &lt;em&gt;T&lt;/em&gt; 도 인접한 것으로 간주합니다. 반대로 만약 &lt;em&gt;S&lt;/em&gt; 와 &lt;em&gt;T&lt;/em&gt; 내의 모든 점들 간에 연결 관계가 없다면, &lt;em&gt;S&lt;/em&gt; 와 &lt;em&gt;T&lt;/em&gt; 는 인접하지 않은 것으로 간주합니다. Superpoint 간의 연결된 edge는 Superedge 라고 부릅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210129-superpoint-graphs/3-feature.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 superedge feature를 정의해야 합니다. Superedge feature은 superpoint 내 점들 간의 모양이나 크기에 따라 정의합니다. 논문에서는 위의 7개 특징에 대한 13차원의 superedge feature를 통해 superpoint의 특징 및 주변 superpoint 간의 연결 관계를 표현했습니다. 이 때 &lt;em&gt;length, surface, volume&lt;/em&gt; 등의 feature은 x,y,z 좌표값의 covariance matrix에 대한 eigenvalue를 통해 principle component에 대한 크기를 계산하고, 이 eigenvalue의 곱으로(각각 &lt;em&gt;e1&lt;/em&gt; , &lt;em&gt;e1 x e2&lt;/em&gt; , &lt;em&gt;e1 x e2 x e3&lt;/em&gt;) 표현했습니다. 또한 centroid offset 이나 length ratio 등은 graph의 방향에 따라 값이 달라지기 때문에, superpoint graph는 directed graph의 형태를 띄게 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Superpoint Embedding&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Superpoint 내의 점들은 같은 기하학적 특성을 공유하므로, 각 superpoint 별로 embedding vector를 추출할 수 있습니다. 논문에서는 PointNet을 통해서 superpoint의 contextual information을 추출합니다. 이 때 같은 superpoint 내의 점들은 기하학적으로 간단하고 서로 유사하기 때문에, GPU efficiency를 위해 몇 개의 점들만 골라서 embedding을 해도 reliably represent 할 수 있습니다. 따라서 저자는 128개의 점들을 sampling해서 이에 대해서만 embedding vector를 추출했고, 만약 한 superpoint에 128개 이하의 점이 있다면 그대로 사용했습니다. (PointNet은 max-pooling을 통해서 embedding vector를 추출했기 때문에 점의 개수가 바뀌어도 같은 크기의 embedding vector를 얻을 수 있었습니다.) 다만 점의 개수가 40개 이하인 경우에는 embedding을 0으로 두었는데, superpoint의 대표성이 떨어져서 성능 저하를 유발했기 때문입니다. 이렇게 superpoint 내에서 sub-sampling을 하게 되면 메모리 측면에서 효율적일 뿐만아니라 augmentation을 해주는 효과도 있었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Contextual Segmentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Superpoint, superedge를 통해 superpoint graph를 정의했다면, 이제 이를 graph convolution을 통해 segmentation 해야 합니다. 이는 Gated Graph Neural Networks와 Edge-Conditioned Convolution을 이용해서 진행되었습니다. 간단히 설명드리자면 Gated Recurrent Unit(GRU)를 통해 각 superpoint에 대한 embedding을 update했는데, 이 때 이용되는 incoming message vector를 주변 superpoint와의 graph convolution을 통해서 얻었습니다. Graph convolution은 앞서 말한 edge-conditioned convolution 기반의 방법으로 진행되었는데, multi-layer perceptron을 통해 구현된 filter generating network가 edge feature vector로부터 attention weight을 계산하면, 이 weight를 기반으로 주변 점들의 feature vector를 dynamic하게 더해주었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Training&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Geometric partitioning 단계는 unsupervised하게 학습되었고, superpoint embedding과 contextual segmentation 과정은 supervised하게 동시에 학습되었습니다. Superpoint 내의 점들은 같은 label을 가진 점들로 가정하였기 때문에, 점들의 label들 중 대다수에 해당하는 것으로 지정했습니다. Superpoint graph의 크기가 커서 GPU limit을 뛰어넘는 경우에는, SPG로부터 몇개의 superpoint(512개)만을 sub-sampling해서 크기가 작은 SPG를 형성하고 기존 SPG와 같은 연결 관계(superedge)를 형성한 후에 작은 SPG에 대해서 학습을 진행했습니다. 이렇게 하면 메모리 이슈도 해결할 수 있고, 동시에 data augmentation의 효과도 가져갈 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/210129-superpoint-graphs/5-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다른 논문들에서와 마찬가지로 가장 일반적인 3D semantic point cloud segmentation 평가 지표인 Semantic3D와 S3DIS dataset을 이용한 성능 평가가 진행되었습니다. 성능은 IOU와 overall accuracy로 측정하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Semantic3D&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210129-superpoint-graphs/4-semantic3d-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Semantic3D는 30억개 이상의 점들로 구성된 가장 큰 LiDAR dataset입니다. SPG는 기존의 SOTA 모델보다 12mIOU points나 높은 SOTA의 성능을 보여주었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;S3DIS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210129-superpoint-graphs/6-s3dis-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;S3DIS는 실내 환경에 대한 3D RGB point cloud dataset입니다. Area 5를 제외한 나머지 영역에 대해 학습을 진행했고, area 5를 이용해서 평가하였습니다. 전반적인 성능에 대해 SOTA를 기록했지만, white board와 같은 경우 partitioning 과정에서 wall과 제대로 구별이 되지 않으며 평균보다 낮은 IOU를 기록하기도 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210129-superpoint-graphs/7-voxelization.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 많은 점들에 대한 inference 시간을 줄이기 위해, voxelization 형태의 전처리를 진행하고 결과를 보여주었습니다. 위의 표에서 알 수 있듯이 적절한 크기의 voxel 단위로 점들의 개수를 줄여준 경우에, inference 속도도 빨라지고 정확도도 증가하는 것을 볼 수 있었습니다.&lt;/p&gt;

&lt;h2 id=&quot;ablations&quot;&gt;Ablations&lt;/h2&gt;
&lt;p&gt;SPG 모델에 활용된 여러가지 모듈들의 성능을 검증하기 위해 ablation study가 진행되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210129-superpoint-graphs/8-ablation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;우선 superpoint graph에 대해 graph convolution을 통해서 contextual information을 추출하는 것이 성능 향상에 얼마나 많은 영향을 주었는지를 확인했습니다. 기존 모델을 Perfect model이라고 할 때, superpoint graph를 GRU가 아닌 일반적인 PointNet을 활용해 처리하는 모델을 Unary model로 하여 두 성능을 비교했습니다. 결과는 22mIOU points에 가까운 성능 하락이 발생하여 graph convolution 기반의 모델을 통해 contextual information을 파악하는 것이 얼마나 중요한지를 보여주었습니다.&lt;/p&gt;

&lt;p&gt;그 외에 GRU + ECC를 이용하는 대신 CRF-RNN을 이용해보는 등 CRF를 후처리로 하는 모델들과의 비교, GRU 기반의 구조를 수정한 모델에 대한 성능 비교 등을 진행했습니다. 결과는 SPG Perfect 모델의 압승이었습니다. 중요하진 않은 것 같아서 넘어가겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Superpoint Graph는 많은 점들을 partitioning 과정을 통해 효율적으로 graph convolution 연산에 적용하는 방법을 제시했습니다. 기존과 달리 많은 수의 점들로 구성된 dataset으로 학습을 진행할 수 있었고, 디테일하고 많은 정보량 덕분인지 월등히 좋은 성능을 보여주었습니다. 또한 graph congolution 연산에 적용해 contextual information도 알맞게 추출하여 성능 향상에 기여하였습니다. 많은 점들에 대한 학습을 가능하게 한 실험적인 좋은 논문이라고 생각됩니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.09869&quot;&gt;https://arxiv.org/abs/1711.09869&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://proceedings.mlr.press/v51/landrieu16.html&quot;&gt;http://proceedings.mlr.press/v51/landrieu16.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="3d" /><category term="3d" /><summary type="html">원문 : Landrieu, Loic, and Martin Simonovsky. “Large-scale point cloud semantic segmentation with superpoint graphs.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.</summary></entry><entry><title type="html">Graph Attention Convolution for Point Cloud Semantic Segmentation 리뷰</title><link href="https://rauleun.github.io/GACnet" rel="alternate" type="text/html" title="Graph Attention Convolution for Point Cloud Semantic Segmentation 리뷰" /><published>2021-01-27T09:00:00+09:00</published><updated>2021-01-27T09:00:00+09:00</updated><id>https://rauleun.github.io/GACnet</id><content type="html" xml:base="https://rauleun.github.io/GACnet">&lt;p&gt;원문 : &lt;a href=&quot;https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Graph_Attention_Convolution_for_Point_Cloud_Semantic_Segmentation_CVPR_2019_paper.pdf&quot;&gt;Wang, Lei, et al. “Graph attention convolution for point cloud semantic segmentation.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 Stanford에서 2019년 CVPR에서 발표한 &lt;strong&gt;&lt;em&gt;Graph attention convolution for point cloud semantic segmentation&lt;/em&gt;&lt;/strong&gt; 논문에 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;이 논문은 graph attention convolution 연산을 제안하였는데, 이는 graph convolution kernel에 이웃한 점들과의 연관성에 따라 attention을 가하여 연관성이 높은 점들에 focus된 feature vector를 추출해줄 수 있도록 설계했습니다. 이를 통해 feature contamination을 방지하고 구조적 feature을 잘 추출하여 높은 segmentation 성능을 달성했습니다.
&lt;img src=&quot;assets/images/210127-GACnet/1-example.png&quot; alt=&quot;&quot; /&gt;
3D Point cloud의 semantic segmentation 분야는 PointNet 논문을 기점으로 활발하게 연구되고 있습니다. 최근에는 point cloud를 graph 형태로 표현하여 CNN 기반의 네트워크를 통해 segmentation 하려는 시도들이 많이 있습니다. 하지만 일반적인 graph convolution 연산에 이용하는 convolution kernel은 일정한 값으로 고정되어 있고, 이는 보통 주변 점들의 feature vector를 homogeneous하게 더하여 새로운 feature로 변환해줍니다. 예를 들어, 위의 그림에서 1번 점에 대한 graph convolution output은 1~5번 점들의 feature를 정해진 비율로 더해서 얻게 되고, 이는 1번 점의 클래스와 주변 점들의 클래스(table 또는 chair)를 고려하지 않고 얻은 것이기 때문에 좋은 output feature vector가 아닙니다. 이는 이웃한 점들과의 구조적인 연결 관계를 파악하게 어렵게 만들기 때문에 결과적으로 명확하지 않은 경계선을 만들거나 부분적으로 잘못된 segmentation 영역을 생성하는 등의 문제를 야기합니다.&lt;/p&gt;

&lt;p&gt;이러한 standard convolution kernel의 단점을 해결하기 위해 제안된 것이 graph attention convolution입니다. Graph attention convolution은 convolution 연산이 가해지는 점과 그 주변 점들의 공간적/특징적 정보들을 이용하여 attention weight을 계산하는데, 이는 연관성이 떨어지는 점들이 output feature vector에 관여하는 것을 막아줍니다. 이를 통해 point cloud에 적용하는 convolution kernel의 실질적인 receptive field는 해당하는 점과 주변 점들의 특징에 의해 동적으로 변화하게 됩니다.&lt;/p&gt;

&lt;p&gt;논문에서는 앞서 제안한 graph attention convolution과 graph coarsening 및 graph interpolation 기법을 통해서 graph pyramid network 구조를 구현하였습니다. 그렇다면 graph attention convolution(GAC)부터 GACnet까지 차근차근 살펴보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;graph-attention-convolution&quot;&gt;Graph Attention Convolution&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/210127-GACnet/2-gac.png&quot; alt=&quot;&quot; /&gt;
Point cloud는 각 점들을 vertex로 하고 인접한 점들을 연결한 선은 edge로 하는 graph 형태의 구조로 변환할 수 있습니다. 이 때 각 점은 &lt;em&gt;f&lt;/em&gt; 차원의 feature vector를 가질 수 있습니다. Graph attention convolution 연산은 우선 기존 &lt;em&gt;f&lt;/em&gt; 차원의 input feature vector를 &lt;em&gt;k&lt;/em&gt; 차원의 output feature vector로 변환하는 것으로 시작합니다. 이 변환은 미분 가능한 형태의 어떠한 함수로도 진행할 수 있는데, 논문에서는 multi-layer perceptron을 이용했습니다.&lt;/p&gt;

&lt;p&gt;이제 각 output feature vector에 attention weight을 elementwise하게 곱해서 convolution 연산을 수행할 것입니다. Attention weight은 output feature vector과 같은 &lt;em&gt;k&lt;/em&gt; 차원의 벡터여야 합니다. GAC에서는 점들 간의 좌표 차이와 feature vector 차이를 이용해서 attention weight을 추출하였습니다. 따라서 attention weight을 계산하는 함수는 &lt;em&gt;xyz&lt;/em&gt; 좌표의 3차원에 input feature vector의 &lt;em&gt;k&lt;/em&gt; 차원을 더한 &lt;em&gt;(3+k)&lt;/em&gt; 차원의 input을 받아서 output feature vector의 &lt;em&gt;k&lt;/em&gt; 차원의 output을 도출합니다. Sharing attention mechanism이라고 부르는 위 변환도 마찬가지로 미분가능한 어떠한 함수로도 진행할 수 있으며 논문에서는 multi-layer perceptron을 이용했습니다.&lt;/p&gt;

&lt;p&gt;Attention weight은 output feature 값의 안정성을 위해 exponential normalization 과정을 거치게 됩니다. 이제 위에서 얻은 &lt;em&gt;k&lt;/em&gt; 차원의 output feature vector에 attention weight을 element-wise 곱한 후 학습가능한 bias 값을 더하여서 GAC의 최종 output vector를 얻습니다.&lt;/p&gt;

&lt;p&gt;GAC 연산은 일반적인 graph attention mechanism과 다르게 attention weight을 얻을 때 점들의 위치 정보와 특징 정보의 차이를 동시에 이용한다는 특징이 있습니다. 이를 통해 점들 사이의 위치적 관계를 고려한 attention 값을 얻을 수 있고, 비슷한 특징을 가진 점들에 더 큰 attention을 가할 수도 있습니다. 또한 feature의 channel별로 attention을 가했기 때문에, 이상적으로 channel-wise independent한 feature vector의 특징을 더 잘 살릴 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;gacnet&quot;&gt;GACnet&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/210127-GACnet/3-gacnet.png&quot; alt=&quot;&quot; /&gt;
Feature pyramid network(FPN) 기반의 구조는 image segmentation 또는 object detection 분야에서 흔하게 이용되는 유용한 구조입니다. 논문에서는 이 구조를 차용한 graph pyramid network 형태의 구조를 위의 그림과 같이 구현하였습니다. FPN에서 feature extraction를 위해 활용되었던 convolution layer는 graph attention convolution layer가 수행합니다. 앞서 설명드린 것처럼 GAC layer는 점들의 위치 및 특징 정보를 활용하여 graph의 local feature vector를 잘 추출해낼 수 있습니다.&lt;/p&gt;

&lt;p&gt;이렇게 얻은 local feature vector는 graph coarsening 및 pooling 과정을 통해 하나의 feature vector로 통합되었습니다. Graph coarsening은 PointNet++에서 소개된 방법을 그대로 이용했는데, furthest point sampling algorithm을 적용하여 여러 개의 중심점들을 선정하고, 각 중심점 주위의 점들을 grouping해서 중심점 단위의 group으로 모아주었습니다. 이후 각 중심점 group마다 max 또는 mean pooling을 적용하여 하나의 feature vector를 도출하였습니다.&lt;/p&gt;

&lt;p&gt;Graph pooling을 거치면 graph의 resolution이 작아지게 되는데, segmentation 등의 task에서는 원래 점들과 같은 개수의 feature map을 output으로 얻어야 하기 때문에 작아진 graph를 interpolation을 통해 up-sampling해주는 과정이 필수적입니다. 이를 feature interpolation layer이라고 부르는데, 마찬가지로 PointNet++에서 제안된 spatial distance 기반의 interpolation 방법을 적용하였습니다. (PointNet++ 리뷰를 참고하시면 도움이 됩니다!) GAC 및 graph pooling layer를 통해 학습된 feature vector는 feature interpolation layer를 통해 서서히 finest scale로 복원됩니다. 논문에서는 더 풍부한 semantic feature를 추출하기 위해 interpolation의 각 단계에서 skip-connection을 통해 down-sampling 되기 전의 feature vector와 합쳐주었습니다. 또한 feature refinement를 위해 최종적으로 학습된 feature vector를 GAC layer에 통과해주었습니다.&lt;/p&gt;

&lt;p&gt;Initial feature vector는 점의 높이, RGB, geo-feature로 구성했습니다. Geo-feature란 finest scale graph에서 이웃한 점들에 대한 covariance matrix의 eigenvalue 값으로 정의하였습니다. 각 구성 특징들의 역할은 후에 ablation study에서 다시 설명드리겠습니다. 초기 그래프는 각 점에 대해 특정 반지름 내에 존재하는 점들 중 random하게 &lt;em&gt;K&lt;/em&gt; 개의 점을 sampling하여 연결하여 생성하였습니다. 이 때 kNN이 아니라 random sampling을 통해서 edge를 구성한 이유는 point cloud의 density가 달라지더라도 이와 무관하게 일정한 범위의 점들에 대해 sampling 할 수 있기 때문입니다. 이렇게 되면 이웃한 두 점이 항상 쌍방으로 연결되지는 않게 되고, graph는 방향성이 있는 edge를 가진 directed graph의 형태가 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;gac-and-conditional-random-fieldcrf&quot;&gt;GAC and Conditional Random Field(CRF)&lt;/h2&gt;
&lt;p&gt;Image segmentation 분야의 유명한 네트워크 모델인 DeepLab에서는 명확한 경계선 구분을 위해 conditional random field(CRF) algoritm을 이용한 후처리 방법을 제안하였습니다. 이는 IOU 및 결과물에 대한 artifact reduction에 많은 공헌을 했고 이후에 이를 기준삼아 많은 segmentation 연구에서 CNN의 output에 CRF를 적용했습니다. CRF는 좌표 및 RGB 값이 비슷한 점들을 같은 label로 일치시켜 segmentation 경계선을 깔끔하고 detail하게 만들어주었습니다.&lt;/p&gt;

&lt;p&gt;앞서 설명드린 GAC도 CRF와 마찬가지로 위치 및 특징 정보를 활용하여 feature vector를 추출해주는 역할을 합니다. 특히 input feature vector 간의 차이를 이용하여 attention weight을 계산하기 때문에 비슷한 input feature를 가지는 점들에 대해 일관적인 output feature를 도출합니다. 이는 CRF와 정확히 같은 특징을 공유하기 때문에 GACnet에서는 더 이상 CRF 과정을 거치지 않아도 됩니다. 실제로 CRF model을 RNN 형식으로 구현하여 후처리하는 방법은 CNN과 독립적으로 진행되기 때문에 end-to-end로 결과를 얻을 수 없게 되는 등의 번거로움이 발생합니다. 또한 input feature의 유사도를 기반으로 layer를 거칠 때마다 더 semantic한 feature vector를 추출할 수 있기 때문에 segmentation 성능도 훨씬 더 잘나오게 되는 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;evaluation&quot;&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;논문에서는 GAC 및 GACnet을 검증하기 위해 S3DIS와 Semantic3D라는 두 가지 3D semantic segmentation benchmark를 이용했습니다. GACnet의 성능은 IOU 및 overall accuracy를 이용하여 평가했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;S3DIS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210127-GACnet/7-gacnet-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;S3DIS는 6개의 실내 공간에 대한 3D RGB point cloud dataset입니다. 각 점은 13개 카테고리로 labeling 되어 있습니다. 논문에서는 6개의 공간 중 5번 공간을 testing set으로, 나머지 공간을 training set으로 하여 네트워크를 학습 및 평가하였습니다. 이렇게 이전에 전혀 보지 못한 공간에 대해 test하게 되면 task가 어려워지기 때문에 초기에는 성능이 잘 안나올 수 있지만, 네트워크 모델이 잘 일반화 되었는지를 평가하기에 좋습니다. 각 공간을 방 별로 먼저 분리하고, 각 방을 &lt;em&gt;1.2m x 1.2m&lt;/em&gt; 의 블럭으로 분리하여, 각 블럭 별로 random sampling된 4096 개의 점을 하나의 dataset으로 이용하였습니다. 방은 분리하는 과정에서 가장자리 &lt;em&gt;0.1m&lt;/em&gt; 씩은 물체의 일부밖에 보이지 않을 수 있기 때문에 buffer area로 설정하여 학습 및 loss 계산에 포함하지 않았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210127-GACnet/4-s3dis-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과는 위와 같습니다. GACnet은 대부분의 클래스에서 SOTA의 성능을 보여주었습니다. 특히나 GACnet은 S3DIS dataset에서 검출하기 어려운 벽 위의 창문이나 보드와 같은 클래스들도 잘 검출하였는데, 이는 GAC가 공간 정보 뿐만 아니라 RGB 값을 포함한 특징 정보도 활용하기 때문에 공간적 구조가 명확하지 않더라도 구별을 잘 해낸 것으로 생각합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Semantic3D&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Semantic3D는 LiDAR에서 얻은 약 40억개 이상의 점들로 구성된 3D point cloud dataset입니다. 점들에 대한 feature는 RGB와 intensity 값으로 구성되어 있고, 각 점은 8개의 카테고리 중 하나로 labeling 되어있습니다. 또한 Semantic3D는 외부 풍경에 대한 dataset이기 때문에 일반적으로 물체의 크기가 큽니다. 따라서 논문에서는 공간을 &lt;em&gt;4m x 4m&lt;/em&gt;의 블럭으로 구분하였고, 블럭 별로 4096 개의 점을 sampling하여 하나의 dataset으로 이용하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/210127-GACnet/5-semantic-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GACnet은 Semantic3D dataset에서도 SOTA의 성능을 보여주었습니다. 특히 Semantic3D에서는 차나 건물 등의 물체들이 가려져 있는 경우가 많은데, GACnet은 구조적인 feature learning 덕분인지 가려져 있는 물체에 대해서도 좋은 성능을 보여주었습니다.&lt;/p&gt;

&lt;h2 id=&quot;ablation-study&quot;&gt;Ablation Study&lt;/h2&gt;
&lt;p&gt;GAC 및 GACnet을 자세히 분석/검증하기 위해 논문에서는 몇 가지 항목에 대한 ablation study를 진행했습니다.
&lt;img src=&quot;assets/images/210127-GACnet/6-ablation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GAC 연산의 효율성&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우선 GAC 연산의 효율성을 검증하기 위해 저자는 GACnet의 GAC 부분을 PointNet에서 활용한 max pooling layer로 치환해서 성능을 측정하고 비교했습니다. Max-pooling 함수는 특징을 통합하여 분류하는 object classification 성능은 좋았지만, 정교한 경계선 설정이 중요한 segmentation task에서는 local한 정보들을 많이 소실하여 비교적 성능이 좋지 못했습니다. 반면에 GAC는 두 task 모두 뛰어난 성능을 보여주었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위치 및 특징 정보들의 성능 향상 기여&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GAC에서 attention weight은 위치 좌표 값의 차이와 feature vector 간의 차이를 input으로 계산하였습니다. 저자는 각각을 하나씩 제거하여 얻은 attention weight을 이용하여 성능을 측정해보았는데, 두 경우 모두 성능 하락이 발생했습니다. 특히 점의 높이, RGB, geo-feature 등으로 구성된 feature vector를 제거하였을 때, 명확한 경계선 설정에 어려움을 겪었다고 이야기합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CRF-RNN 과의 비교&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GAC 모듈을 CRF-RNN으로 치환했을 때의 성능도 비교하였습니다. 두 경우 모두 유사한 성능을 보여주었는데, CRF와 GAC가 특징 벡터의 유사도를 이용하여 label을 도출하는 근본적으로 같은 성질을 공유하기 때문으로 보입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;초기 feature vector 구성에 따른 효과&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GAC의 input으로 활용하는 초기 feature vector는 점의 높이, RGB, geo-feature로 구성하였습니다. 각각 성능에 어떤 영향을 주는지를 분석하기 위해, 특정 component를 제외하고 성능을 측정하였습니다. 결과는 전반적인 성능 하락이 발생하여 각 component가 성능에 주요한 역할을 하는 것을 할 수 있었습니다. 
&lt;img src=&quot;assets/images/210127-GACnet/8-geo-feature.png&quot; alt=&quot;&quot; /&gt;
이 중 흥미로운 결과가 있었는데, geo-feature가 training accuracy에는 별다른 영향을 주지 않았는데 test accuracy에는 비교적 큰 성능 향상에 기여했습니다. 이는 covariance matrix의 eigenvalue로부터 추출한 geo-feature 값이 전반적인 low-level feature에 대한 정보를 포함하고 있고, 결과적으로 네트워크의 일반화에 기여한 것으로 보입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 소실 및 잡음에 대한 강도 실험
&lt;img src=&quot;assets/images/210127-GACnet/9-robustness-test.png&quot; alt=&quot;&quot; /&gt;
마지막으로 데이터의 일부가 소실되거나 Gaussian noise가 추가되었을 때 classification 성능이 어떻게 변화하는지를 실험하였습니다. GAC 모듈을 max-pooling 함수로 치환하여 비교하였는데, 두 경우 모두 GACnet이 훨씬 더 robust한 결과를 보여주었습니다. 아마 max-pooling 함수를 이용하게 되면, noise 값이 크게 튀는 경우에 이를 대표적인 feature 값으로 인식되어 classification 정확도를 낮추지 않았을까 생각됩니다. 반면에 GAC는 상대적 위치정보 뿐만아니라 여러 성분들(RGB 등)로 구성된 특징 정보를 활용하기 때문에 (정보량이 많기 때문에), 방해 요소들이 있어도 robust한 결과를 보여주는 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Graph attention convolution은 주변 점들에 따라 attention weight을 다르게 가하는 방식을 통해 dynamic한 receptive field를 가지는 convolution kernel를 생성할 수 있었고, 이를 통해 feature vector를 추출했습니다. Edge convolution 등의 방법과 유사하면서도, 점들의 특징 벡터의 차이를 이용하여 비슷한 label을 가진 점들을 확실하게 일치시켜 주는 (CRF가 기존에 해주던 방식의) 연산 방식이 SOTA의 성능을 만들 수 있지 않았나 생각이 듭니다. 긴 글 읽어주셔서 감사합니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Graph_Attention_Convolution_for_Point_Cloud_Semantic_Segmentation_CVPR_2019_paper.pdf&quot;&gt;https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Graph_Attention_Convolution_for_Point_Cloud_Semantic_Segmentation_CVPR_2019_paper.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/yanx27/GACNet&quot;&gt;https://github.com/yanx27/GACNet&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="3d" /><category term="3d" /><summary type="html">원문 : Wang, Lei, et al. “Graph attention convolution for point cloud semantic segmentation.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.</summary></entry><entry><title type="html">PointNet++ - Deep Hierarchical Feature Learning on Point Sets in a Metric Space 리뷰</title><link href="https://rauleun.github.io/PointNet++" rel="alternate" type="text/html" title="PointNet++ - Deep Hierarchical Feature Learning on Point Sets in a Metric Space 리뷰" /><published>2021-01-21T09:00:00+09:00</published><updated>2021-01-21T09:00:00+09:00</updated><id>https://rauleun.github.io/PointNet++</id><content type="html" xml:base="https://rauleun.github.io/PointNet++">&lt;p&gt;원문 : &lt;a href=&quot;https://papers.nips.cc/paper/2017/file/d8bf84be3800d12f74d8b05e9b89836f-Paper.pdf&quot;&gt;Qi, Charles Ruizhongtai, et al. “Pointnet++: Deep hierarchical feature learning on point sets in a metric space.” Advances in neural information processing systems. 2017.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 Stanford에서 2017년 NIPS에 발표한 &lt;strong&gt;&lt;em&gt;Pointnet++: Deep hierarchical feature learning on point sets in a metric space&lt;/em&gt;&lt;/strong&gt; 논문에 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;이 논문은 Point cloud 형식의 데이터를 Deep learning 분야에 적용시킨 선구적인 논문인 PointNet의 후속편으로, local한 특징을 잡아내지 못하는 기존의 PointNet을 보완하여 classification 및 segmentation 성능을 크게 끌어올렸습니다.&lt;/p&gt;

&lt;p&gt;그럼 시작하겠습니다!&lt;/p&gt;
&lt;h2 id=&quot;pointnet&quot;&gt;PointNet&lt;/h2&gt;
&lt;p&gt;PointNet++에 대하여 설명드리기 전에, 전편인 PointNet에 관해서 간단히 짚고 넘어가겠습니다. (자세한 설명은 PointNet 논문 리뷰를 참고해주세요.) Point cloud는 3차원 공간 내의 물체를 표현하기 위한 데이터의 한 형식으로 각 점들에 대한 좌표값으로 구성되어 있습니다. Point cloud는 sparse한 점들의 집합이기 때문에 계산량 및 메모리 차원에서 효율적이지만, 순서가 없는 집합 형태의 데이터이기 때문에 neural network가 이를 처리하려면 permutation-invariant한 특성을 가진 layer를 포함하고 있어야 했습니다. PointNet에서는 symmetric function 중의 하나인 max-pooling 함수를 활용하여 point cloud 데이터에 대한 global한 feature vector를 추출하였습니다. 하지만 max-pooling 함수의 특성상 최대값을 제외한 local한 정보들을 소실될 수밖에 없고 이는 정교한 경계선 설정이 중요한 segmentation task 등에서 성능 저하의 요인이 되었습니다. PointNet++에서는 몇 가지 구조를 제안하여 local한 feature vector를 추출하였습니다.&lt;/p&gt;

&lt;p&gt;Local한 특징을 추출하는 것은 중요합니다. CNN에서도 다양한 receptive field를 가지는 convolution kernel을 활용함으로써 local한 특징을 추출하였고, 이는 2D image들에 대한 폭발적인 성능 향상을 이뤄냈습니다. PointNet++는 계층적 구조의 neural network를 활용하여 다양한 scale의 local feature를 추출하였고, 이를 통합하여 SOTA의 classification 및 segmentation 성능을 기록할 수 있었습니다. 그럼 PointNet++에 대해 좀 더 자세히 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;pointnet-1&quot;&gt;PointNet++&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/210121-pointnet++/1-pointnet++.png&quot; alt=&quot;&quot; /&gt;
PointNet++는 &lt;strong&gt;Set abstraction layer&lt;/strong&gt;과 &lt;strong&gt;Density adaptive layer&lt;/strong&gt;로 구성되어 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;set-abstraction&quot;&gt;Set Abstraction&lt;/h2&gt;
&lt;p&gt;PointNet++에서는 set abstraction이라고 부르는 과정을 통해 point cloud의 local feature를 추출하였습니다. Set abstraction을 거치면, point 들의 집합은 이전보다 적은 수의 점들로 구성된 point cloud로 추상화되며, semantic한 정보를 담게 됩니다.&lt;/p&gt;

&lt;p&gt;Set abstraction은 세 단계로 구분할 수 있습니다. 우선 sampling 단계에서는 point cloud의 local한 부분집합의 중심에 해당하는 중요한 몇 개의 점들을 선택합니다. 이후 grouping 단계에서는 sampling 단계에서 찾은 중요한 몇 개의 점들과 이웃한 점들을 찾고 하나의 집합으로 구성합니다. 마지막으로 pointnet 단계에서는 local한 점들의 집합에 대한 패턴을 encoding하여 feature vector를 추출합니다.&lt;/p&gt;

&lt;p&gt;예를 들어 Point cloud가 &lt;em&gt;N&lt;/em&gt; 개의 점들로 구성되어 있고 각 점은 &lt;em&gt;d&lt;/em&gt; 차원의 좌표를 가지며 &lt;em&gt;C&lt;/em&gt; 차원의 feature vector를 가진다고 가정하겠습니다. Set abstraction 과정을 거치면 &lt;em&gt;N&lt;/em&gt; x &lt;em&gt;(d+C)&lt;/em&gt; 크기의 input 행렬이 &lt;em&gt;N’&lt;/em&gt; x &lt;em&gt;(d+C’)&lt;/em&gt; 크기의 행렬로 변환되어 출력됩니다. 이 때 &lt;em&gt;N’&lt;/em&gt; 는 subsampling된 점들의 개수이고, &lt;em&gt;C’&lt;/em&gt; 는 중심점 행렬의 feature vector의 차원입니다.&lt;/p&gt;

&lt;p&gt;Sampling 단계에서는 &lt;em&gt;N&lt;/em&gt; 개의 점들 중 &lt;em&gt;N’&lt;/em&gt; 개의 점을 중심점으로 선택합니다. 이 &lt;em&gt;N’&lt;/em&gt; 개의 점들은 전체 점들 중 나머지 점들과의 거리가 가장 먼 점들로 구성됩니다. 이때 이 거리라는 개념은 Uclidian distance 일 수도 있고 그 외 다른 거리 관련 metric일 수도 있습니다. 논문에서는 이 거리가 가장 먼 점들의 집합을 Farthest point sampling (FPS) 알고리즘을 반복적으로 적용해 얻었다고 설명하였습니다. 또한, 이렇게 서로 최대한 떨어져 있는 점들을 선택하게 되면 random sampling을 통해서 점들을 선택하는 것보다 더 일반적이고 전체적인 범위의 point들을 얻을 수 있습니다.&lt;/p&gt;

&lt;p&gt;Grouping 단계에서는 sampling 단계에서 추출한 &lt;em&gt;N’&lt;/em&gt; 개 중심점들의 주변 점들을 선택하여 local한 영역으로 묶어줍니다. 각 중심점과 묶이는 주변 점들의 개수는 영역마다 다를 수 있는데, 후에 설명드릴 pointnet 단계에서 점들의 개수와 상관 없이 같은 크기의 feature vector로 변환해주기 때문입니다. 또한 이웃한 점들을 선택하는 방식도 두 가지로 나뉠 수 있습니다. 우선, ball query 방식은 반지름 &lt;em&gt;r&lt;/em&gt; 을 정해 이 반지름 내에 있는 점들을 모두 이웃한 점으로 선택하는 방식입니다. 또한, kNN 방식은 정해진 &lt;em&gt;K&lt;/em&gt; 라는 개수의 가장 가까운 점들을 이웃한 점으로 선택하는 방식입니다. 논문에서는 ball query 방식을 선택했는데, kNN과 비교했을 때 정해진 크기의 지역을 확실하게 표현할 수 있기 때문입니다. 이는 일정하게 sampling되지 않은 point cloud 데이터에서 영역 별로 범위가 달라지는 문제를 방지할 수 있게 됩니다.&lt;/p&gt;

&lt;p&gt;마지막으로 pointnet 단계에서는 각 local한 영역에 대해 특징 정보를 encoding한 하나의 feature vector를 추출할 수 있습니다. 각 중심점(총 &lt;em&gt;N’&lt;/em&gt; 개)별로 생성된 &lt;em&gt;K&lt;/em&gt; 개의 이웃한 점들에 대한 &lt;em&gt;(d+C)&lt;/em&gt; 크기의 feature vector를 행렬로 표현하면 &lt;em&gt;N’&lt;/em&gt; x &lt;em&gt;K&lt;/em&gt; x &lt;em&gt;(d+C’)&lt;/em&gt; 크기의 행렬이 되는데, 이 행렬이 pointnet 단계를 거치면 &lt;em&gt;N’&lt;/em&gt;x&lt;em&gt;(d+C’)&lt;/em&gt; 크기의 feature vector로 변환됩니다. 이 때, 점들의 좌표값은 중심점과의 상대적인 거리의 차이에 대한 값이 들어가게 되는데, 이를 통해 점들 사이의 위치적 관계에 대한 정보를 잡아낼 수 있기 때문입니다.&lt;/p&gt;

&lt;h2 id=&quot;density-adaptive-feature-learning&quot;&gt;Density Adaptive Feature Learning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/210121-pointnet++/2-nonuniform-pointcloud.png&quot; alt=&quot;&quot; /&gt;
Point cloud 데이터는 위의 그림처럼 non-uniform한 밀도 분포를 가지는 것이 대부분입니다. 이렇게 일정하지 않은 점들의 분포는 point cloud의 특징에 대한 학습을 어렵게 만드는데, density가 높은 point cloud에 대해 학습한 네트워크는 sparse한 점들의 point cloud를 만났을 때 정보가 부족하다고 느끼고 특징을 제대로 표현하지 못하기 때문입니다. (그 반대의 경우도 마찬가지입니다.) 논문에서는 이를 해결하기 위해 point cloud의 sampling density를 변화시키며 학습하였습니다. 또한, 다양한 scale의 point cloud에서 feature vector를 추출하는 multi-scale feature extraction 구조를 활용하였는데, 저자는 이를 &lt;em&gt;density adaptive layer&lt;/em&gt; 이라고 표현했습니다. 다양한 크기의 density를 가지는 point cloud를 학습하는 두 가지 방법에 대해 소개하겠습니다.
&lt;img src=&quot;assets/images/210121-pointnet++/3-grouping.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Multi-scale grouping (MSG)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우선 grouping 단계를 다양한 scale로 여러 번 적용하여 하나의 중심점에 대해 여러 scale의 point group을 얻는 방법이 있습니다. 각 point group에서 각각 추출한 feature vector를 이어붙이면(concatenate), multi-scale feature vector를 얻을 수 있게 됩니다. 이 때, 각 point group은 임의의 dropout ratio를 선택하여 그 비율에 맞게 random하게 down-sampling(dropout) 하여 각 point group마다 서로 다른 scale로 균일하지 않은 density를 가지게끔 변환해주었습니다. 이러한 과정을 거치면 다양한 sparsity와 서로 다른 uniformity를 가지는 점들을 얻을 수 있습니다. 하지만 MSG는 각 중심점들과 그 이웃한 점들이 모두 pointnet을 거쳐야 하므로 게산량 차원에서 아주 비효율적이고 time-consuming하다는 단점이 있습니다. 논문에서는 이를 보완하기 위해 multi-resolution grouping을 제안하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Multi-resolution grouping (MRG)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;MRG는 MSG의 단점을 보완한 grouping 방식입니다. MRG는 서로 다른 scale로 얻은 두 feature vector를 이어붙여서(concatenate) multi-scale feature vector를 얻습니다. 이 때, 첫 번째 vector는 local group에 해당하는 점들 전체에 대해 pointnet 단계를 거쳐서 얻고, 두 번째 vector는 local group에 대해 그보다 한 단계 아래의 sub-region에서 얻은 feature를 종합하여 얻습니다. 저자는, 만약 input으로 들어오는 point cloud의 density가 낮다면, 첫 번째 vector에 의해 전반적인 특징에 대한 정보를 추출할 수 있고, density가 높다면, sub-region에 대한 feature가 높은 resolution 더 디테일한 특징 정보를 제공할 수 있다고 이야기합니다. 따라서 두 vector를 모두 이용하게 되면 여러 density의 point cloud에 대해서 모두 대응할 수 있으며, 계산량 측면에서도 효율적이라고 말합니다.&lt;/p&gt;

&lt;h2 id=&quot;point-feature-propagation&quot;&gt;Point Feature Propagation&lt;/h2&gt;
&lt;p&gt;Set abstracion layer를 거치게 되면, sampling 단계에 의해 point cloud의 크기가 줄어들게 됩니다. 이렇게 얻은 feature vector를 segmentation task에 활용하려면 다시 원래의 크기로 복원해주어야 합니다. 복원해주지 않고 set abstraction을 하기 위해 모든 점들을 중심점으로 지정해서 feature aggregation을 해주는 방법도 있지만, 이는 computation cost가 너무 많이 들기 때문에 논문에서는 point cloud를 down-sampling하고 다시 interpolation 기반의 방법을 통해 up-sampling하는 방식을 제안하고 있습니다.&lt;/p&gt;

&lt;p&gt;구체적으로, 이전 점들에 대한 feature vector로부터 (&lt;em&gt;1/거리값)&lt;/em&gt; 으로 weighting을 가해서 interpolation하는 방법을 이용하였습니다. 또한 down-sampling 되기 전의 feature vector를 skip-connection을 통해 concatenate하여 부족할 수도 있는 정보량을 보충해주었습니다. Interpolation 과정은 원래 point의 개수로 맞춰질 때까지 반복해주었고, 결과로 얻은 feature vector를 통해서 segmentation task를 수행해주었습니다.&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;PointNet++는 MNIST(2D Object), ModelNet40(3D Object), ScanNet(3D Scene) 등의 다양한 데이터셋에 대한 evaluation 과정을 통해 classifiaction 및 segmentation task에서 성능을 증명하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;MNIST
&lt;img src=&quot;assets/images/210121-pointnet++/4-mnist-result.png&quot; alt=&quot;&quot; /&gt;
MNIST 데이터셋은 손글씨 숫자에 대한 60,000개 이상의 image입니다. PointNet++는 2D image의 좌표를 2D point cloud 형태로 변환하여 input으로 사용했는데, 기존 PointNet과 비교했을 때 error rate이 30% 이상 감소하는 등의 성능 향상을 보여주었습니다. 또한 기존 CNN 기반의 모델들과 비교했을 때도 더 좋은 성능을 보이기도 했습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ModelNet40
&lt;img src=&quot;assets/images/210121-pointnet++/5-modelnet-result.png&quot; alt=&quot;&quot; /&gt;
ModelNet40 데이터셋은 40개의 클래스에 대한 CAD 모델입니다. CAD 모델은 3D Mesh 형태를 띄고 있기 때문에, 논문에서는 mesh의 표면을 sampling하여 3D point cloud 형태로 변환한 후에 PointNet++의 input으로 사용하였습니다. 또한 모델 구조는 3단계의 계층 단계에 3개의 Fully connected layer를 이어붙여서 구성했으며, 모든 point들의 좌표는 반지름 1의 구 안에 들어오게끔 하여 normalization을 해주었습니다. PointNet++는 3D classification task에서도 기존의 SOTA 모델로 알려진 MVCNN의 성능을 크게 뛰어넘었습니다.
&lt;img src=&quot;assets/images/210121-pointnet++/6-grouping-result.png&quot; alt=&quot;&quot; /&gt;
또한 ModelNet 데이터셋을 활용하여 Density adaptive layer의 성능을 측정하는 ablation study를 진행했습니다. 위의 그림을 보면, 1024개의 점에 대한 point cloud로부터 random하게 점을 지워서 512, 256, 128개로 down-sampling하였습니다. 점의 개수가 다른 point cloud를 PointNet 및 PointNet++의 input으로 넣어주었을 때, 앞서 설명드린 density aadaptive layer (MSG 또는 MRG)를 적용시켜 multi-scale로 학습한 모델들은 점의 개수가 달라져도 robust한 결과를 보여주었습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ScanNet&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ScanNet 데이터셋은 실내 환경에 대한 1500개 이상의 3D point cloud 데이터로 구성되어 있습니다. 각각의 점들에는 해당 점이 어떤 물체에 속해 있는지에 대한 segmentation label이 달려 있습니다. PointNet++는 ScanNet에 대한 segmentation task에서도 아주 뛰어난 결과를 보여주었습니다. 계층적 구조를 통한 local한 feature 학습이 다양한 scale의 scene을 이해하는데 중요하다고 해석할 수 있을 것 같습니다. 
&lt;img src=&quot;assets/images/210121-pointnet++/8-scannet-result.png&quot; alt=&quot;&quot; /&gt;
ScanNet에서도 sampling density가 달라졌을 때 robust한 결과를 도출할 수 있는지 실험하였습니다. ScanNet 데이터를 non-uniform한 sampling density로 줄여서 학습한 뒤에 결과를 확인해보았습니다. 앞선 ModelNet40을 이용한 실험 결과와 마찬가지로, MRG 네트워크가 Single-scale grouping을 통해 학습한 네트워크보다 다양한 density의 데이터들에 대해 훨씬 더 좋은 결과를 보여주었습니다. 
&lt;img src=&quot;assets/images/210121-pointnet++/7-grouping-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;PointNet과 더불어 PointNet++는 이전에 classification이나 detection 분야에서 활용되었던 multi-scale feature learning 기법을 point cloud 데이터에 적용시켜 급격한 성능 향상을 만들었습니다. 또한 Graph의 크기를 줄이는 graph coarsening이나 다시 graph의 크기를 키우는 point feature propagation 등 다양한 개념이 제시된 논문이라 의미가 크다고 생각합니다. 다음 번에는 이를 기반으로 attention 메커니즘을 적용시킨 논문을 한번 리뷰해보겠습니다. 읽어주셔서 감사합니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://stanford.edu/~rqi/pointnet2/&quot;&gt;http://stanford.edu/~rqi/pointnet2/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/charlesq34/pointnet2&quot;&gt;https://github.com/charlesq34/pointnet2&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="3d" /><category term="3d" /><summary type="html">원문 : Qi, Charles Ruizhongtai, et al. “Pointnet++: Deep hierarchical feature learning on point sets in a metric space.” Advances in neural information processing systems. 2017.</summary></entry><entry><title type="html">Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs 리뷰</title><link href="https://rauleun.github.io/Edge-Conditioned-Convolution" rel="alternate" type="text/html" title="Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs 리뷰" /><published>2021-01-20T09:00:00+09:00</published><updated>2021-01-20T09:00:00+09:00</updated><id>https://rauleun.github.io/Edge-Conditioned-Convolution</id><content type="html" xml:base="https://rauleun.github.io/Edge-Conditioned-Convolution">&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/1704.02901&quot;&gt;Simonovsky, Martin, and Nikos Komodakis. “Dynamic edge-conditioned filters in convolutional neural networks on graphs.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 ENPC에서 2017년 CVPR에 발표한 &lt;strong&gt;&lt;em&gt;Dynamic edge-conditioned filters in convolutional neural networks on graphs&lt;/em&gt;&lt;/strong&gt; 논문에 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;이 논문은 Point cloud 등의 graph 구조로 표현 가능한 데이터에서 convolution 형태의 연산을 통해 feature vector를 추출하는 하나의 방법에 대해 제시하고 있습니다.&lt;/p&gt;

&lt;p&gt;그럼 시작하겠습니다!&lt;/p&gt;
&lt;h2 id=&quot;graph-convolution&quot;&gt;Graph Convolution&lt;/h2&gt;
&lt;p&gt;Convolution(합성곱) 연산은 2D image에 대한 내재된 feature 벡터를 잘 추출해줌으로써 classification, segmentation 등의 여러 task들에 대한 성능을 폭발적으로 끌어올렸습니다. 학계에서는 2D image 등의 Uclidian 공간에 대한 데이터 뿐만 아니라 graph 등 non-Uclidian 공간 상의 데이터도 convolution 연산을 통해 처리할 수 있지 않을까에 대해 많이 고민했습니다.&lt;/p&gt;

&lt;p&gt;이러한 고민의 결과로 인접한 node 간의 특징 벡터를 모아주는 graph convolution 연산을 발견하였고, 이는 graph 형태로 표현 가능한 3D modeling, biological molecule, social network 등의 데이터에 활용되었습니다. 하지만 기존의 방법대로는 한 점과 인접한 점들의 feature 벡터를 균일하게(homogeneous) 더해줄 수 밖에 없었고, 이는 점들 간의 연관성의 정도를 전혀 고려하지 않은 연산이었습니다. (일반적인 discrete convolution으로 생각해보면, uniform function만을 filter로 사용하는 형태였습니다.)&lt;/p&gt;

&lt;p&gt;이를 보완하기 위해 논문에서는 점과 점을 연결한 edge에 점들 간의 관계를 나타내는 label을 부여해서 weight parameter처럼 활용하였습니다. 이렇게 edge label을 이용하여 graph convolution을 하게 되면, 단순히 점들을 homogeneous하게 더하는 것이 아니라 점들 간의 연관성을 고려하여 더해주기 때문에 주변 점들과의 관계가 반영된 feature 벡터를 추출할 수 있다고 합니다. 또한 이 feature vector를 이용해서 graph 또는 vertex 단위로 classification을 했을 때 점들의 관계 및 분포에 대한 정보가 녹아있어 정확도가 향상되었다고 합니다. 본문에서는 이렇게 edge label을 이용한 convolution 연산을 edge-conditioned convolution(ECC)라고 부릅니다.&lt;/p&gt;

&lt;h2 id=&quot;point-cloud&quot;&gt;Point cloud&lt;/h2&gt;
&lt;p&gt;Point cloud는 3D 물체를 표현하기 위한 형식 중의 하나입니다. 원래 point cloud는 일정한 형식이 없는 집합 형태의 데이터이기 때문에 neural network의 input으로 활용하기 어려웠습니다. 하지만 특정 점에 대해 정의된 거리(r) 내에 있는 점들 중 K-nearest neighbors 알고리즘을 적용해서 인접한 점들을 찾은 뒤, 서로 연결해서 graph 형태로 변환하게 되면 graph convolution을 적용할 수 있습니다. 따라서 논문에서는 여러 종류의 graph 데이터들 중 주로 point cloud를 graph로 변환한 데이터를 활용했습니다. Point cloud는 물체나 풍경을 3D로 표현했다는 특성상 graph 또는 vertex 단위로 label이 존재하기 때문에 graph convolution의 성능을 측정하기에 적절하기도 합니다. 또한 최근에는 RGB-D 카메라나 LiDaR의 출력 형식으로 사용되기 때문에 범용적이기도 합니다.&lt;/p&gt;

&lt;h2 id=&quot;edge-conditioned-convolution-ecc&quot;&gt;Edge-conditioned Convolution (ECC)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/210120-ECC/1-edge-convolution.png&quot; alt=&quot;&quot; /&gt;
Edge-conditioned convolution 연산 과정은 그리 어렵지 않습니다. Point cloud 데이터를 graph 형태로 변환하여 &lt;em&gt;n&lt;/em&gt;개의 node와 &lt;em&gt;m&lt;/em&gt;개의 edge를 얻었다고 가정하겠습니다. 이 때 node의 feature vector가 &lt;em&gt;l&lt;/em&gt; 차원, edge의 feature vector가 &lt;em&gt;s&lt;/em&gt; 차원이라고 하면 우리는 edge의 feature vector로부터 node feature vector의 transformation matrix (&lt;em&gt;l&lt;/em&gt;x&lt;em&gt;l&lt;/em&gt; 차원)를 얻는 미분 가능한 함수를 정의하고자 합니다. 논문에서는 가장 간단한 multi-layer perceptron을 활용하였는데, input이 &lt;em&gt;s&lt;/em&gt;차원 &amp;amp; output이 &lt;em&gt;l&lt;/em&gt;x&lt;em&gt;l&lt;/em&gt; 차원인 linear layer입니다. 이렇게 각 node마다 &lt;em&gt;l&lt;/em&gt;x&lt;em&gt;l&lt;/em&gt; 차원의 “edge-specific weights”를 얻을 수 있고, 이는 edge feature vector에서 추출한 행렬이기 때문에 점들 사이의 관계를 담고 있습니다. 이렇게 얻은 weight을 이웃한 각 node feature vector에 곱해주고 normalize하면 edge-conditioned convolution을 거친 해당 점의 feature vector를 얻을 수 있습니다.
&lt;img src=&quot;assets/images/210120-ECC/2-one-hot-edge.png&quot; alt=&quot;&quot; /&gt;
각 edge feature vector를 순서에 맞는 one-hot vector로 설정하면 edge-conditioned convolution 연산은 uniform function에 대한 convolution과 같아집니다. 위의 그림에서 ECC는 filter size가 3인 1차원의 discrete convolution과 정확히 같아지는 것을 확인할 수 있습니다.
ECC의 특징 중의 하나가 multi-hop convolution이 불가능하다는 점입니다. 다른 graph convolution 연산의 경우에는 인접 행렬을 여러번 곱해서 multi-hop의 범위를 가지는 node에 대해서도 feature aggregation을 할 수가 있지만, ECC는 인접 행렬을 이용하지 않기 때문에 multi-hop 연산이 불가능합니다. 하지만 저자는 일반적인 2D convolution에서도 크기가 큰 filter를 이용하는 것보다 3x3 크기의 filter를 여러개 이어붙이는 것이 더 좋은 feature를 추출하기 때문에 ECC layer도 여러번 반복하면 multi-hop convolution보다 좋은 성능을 낼 것이라고 이야기합니다.
ECC layer의 끝에는 다른 convolution layer와 마찬가지로 batch normalization layer를 붙여주어 학습을 효율적으로 진행할 수 있게 하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;deep-network-with-ecc&quot;&gt;Deep network with ECC&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/210120-ECC/3-network-architecture.png&quot; alt=&quot;&quot; /&gt;
ECC 연산을 통해 2D image data에 대한 neural network와 비슷한 구조를 graph 구조에 대해서도 구현할 수 있습니다. 위 그림은 ECC를 이용한 convolution layer와 graph-pooling 및 coarsening 과정을 이용한 pooling layer를 이어붙여 deep neural network를 구현한 그림입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Graph pooling &amp;amp; coarsening
ECC는 nearest neighborhood를 통해 정의된 그래프의 구조를 그대로 유지한 결과를 출력합니다. 하지만 classification task의 출력 형식인 C(number of class)차원의 출력 벡터를 얻기 위해서는 graph의 크기를 줄여서 node feature을 합쳐주어야 합니다. Graph의 크기를 줄이는 과정을 graph coarsening, node feature를 합치는 과정을 graph pooling이라고 부릅니다. Coarsening을 반복하게 되면 결국에는 서로 연결되지 않은 몇 개의 node들만 남게 됩니다. 이 때 각 node들은 self-loop을 가지고 있기 때문에 여전히 graph의 형태를 띈다고 할 수 있으며 global max pooling 등의 과정을 통해 마지막 남은 feature vector를 합쳐줄 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Graph coarsening에는 다양한 알고리즘들이 활용될 수 있는데, 논문에서는 특정한 resolution을 가지는 3차원의 grid를 생성해서 해당 grid 안의 점들을 하나로 모아주는 VoxelGrid 알고리즘을 이용했습니다. 합쳐진 점들에 대해서는 다시 nearest neighbor을 통해 graph로 변환해줍니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Edge label
Edge label은 해당 edge와 연결된 두 vertex 좌표값의 차이로 설정했습니다. Cartesian 및 Spherical coordinate으로 변환하여 총 6차원의 edge feature vector를 활용하였습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Augmentation
학습할 때에는 dataset의 규모가 크지 않기 때문에 여러 방법으로 augmentation을 하여 overfitting을 방지하였습니다. 논문에서는 point cloud를 임의로 회전시키거나, 크기를 변화시키거나, 특정 축으로 대칭시키거나, 몇개의 점을 지우는 등의 방법을 통해 데이터 다양성을 확보했다고 주장합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;ECC는 다양한 형태의 point cloud 및 graph classification 실험을 통해 성능을 보여주었습니다. 오늘은 대표적으로 ModelNet 데이터셋과 MNIST 데이터셋을 활용한 실험을 소개하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ModelNet
&lt;img src=&quot;assets/images/210120-ECC/4-modelnet-result.png&quot; alt=&quot;&quot; /&gt;
ModelNet 데이터셋은 물체에 대한 3D Mesh 형태의 데이터입니다. 카테고리 개수에 따라 ModelNet10과 ModelNet40으로 구분되며 각각 4000개, 10000개 정도의 학습 데이터가 존재합니다. 논문에서는 Mesh 형태의 데이터의 표면에서 uniform하게 1000개씩의 point를 sampling하여 point cloud 형태로 변환해주었습니다. 신경망 구조는 &lt;strong&gt;&lt;em&gt;ECC(16)-ECC(32)-MP(2.5/32,7.5/32)-ECC(32)-ECC(32)-MP(7.5/32,22.5/32)-ECC(64)-GMP-FC(64)-Dropout(0.2)-FC(10 or 40)&lt;/em&gt;&lt;/strong&gt; 의 형태를 이용하였고 100 epoch의 학습을 진행하였습니다. Classification에 대한 전반적인 accuracy는 SOTA만큼은 아니지만 경쟁력 있는 수준을 보여주었습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MNIST
논문에서는 숫자에 대한 28x28 크기의 이미지 데이터셋인 MNIST 데이터셋을 이용한 성능도 측정하였습니다. 우선 ECC를 적용할 수 있게 2D image를 &lt;em&gt;(x, y, 0)&lt;/em&gt;의 좌표를 가지는 point cloud 형태로 변환하고 nearest neighbor 알고리즘을 통해 다시 graph 형태로 변환하였습니다. 여기서는 &lt;strong&gt;&lt;em&gt;C(16)-MP(2,3.4)-C(32)-MP(4,6.8)-C(64)-MP(8,30)-C(128)-D(0.5)-FC(10)&lt;/em&gt;&lt;/strong&gt; 형태의 네트워크 구조를 활용하여 20 epoch만큼 학습을 진행하였습니다.
&lt;img src=&quot;assets/images/210120-ECC/5-mnist-result.png&quot; alt=&quot;&quot; /&gt;
학습 결과는 위와 같습니다. 기존의 baseline 모델들과 비교해도 괜찮은 결과를 도출하였습니다. 또한 2D image에서 어두운 부분을 제외하고 graph 형태로 변환하여 학습을 시켜도 비슷한 결과를 도출하였습니다. 이는 graph의 형태가 바뀌어도 neural network가 학습 및 추론을 안정적으로 할 수 있다는 것을 의미합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;논문에서는 edge label을 처음으로 사용한 Edge-conditioned Convolution 연산을 제시하였고, 이를 활용하여 graph 형태의 데이터를 위한 feed-forward network를 구성하였습니다. 추후에 진행되는 attention 기반의 graph convolution 등의 연구의 기반이 되는 중요한 연구라고 생각합니다. 읽어주셔서 감사합니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://openaccess.thecvf.com/content_cvpr_2017/html/Simonovsky_Dynamic_Edge-Conditioned_Filters_CVPR_2017_paper.html&quot;&gt;https://openaccess.thecvf.com/content_cvpr_2017/html/Simonovsky_Dynamic_Edge-Conditioned_Filters_CVPR_2017_paper.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="3d" /><category term="3d" /><summary type="html">원문 : Simonovsky, Martin, and Nikos Komodakis. “Dynamic edge-conditioned filters in convolutional neural networks on graphs.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.</summary></entry><entry><title type="html">BERT - Pretraining of Deep Bidirectional Transformers for Language Understanding 리뷰</title><link href="https://rauleun.github.io/BERT" rel="alternate" type="text/html" title="BERT - Pretraining of Deep Bidirectional Transformers for Language Understanding 리뷰" /><published>2020-11-03T09:00:00+09:00</published><updated>2020-11-03T09:00:00+09:00</updated><id>https://rauleun.github.io/BERT</id><content type="html" xml:base="https://rauleun.github.io/BERT">&lt;p&gt;원문 : &lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;Devlin, Jacob, et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” arXiv preprint arXiv:1810.04805 (2018).
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/201102-BERT/bert.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 Google AI Language에서 2019년 arxiv에 발표한 &lt;strong&gt;&lt;em&gt;Bert: Pre-training of deep bidirectional transformers for language understanding&lt;/em&gt;&lt;/strong&gt; 논문에 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;이 논문은 Transformer Encoder 구조를 활용하여 자연어에 대한 representation을 pre-training 하였습니다. Unsupervised learning 방식으로 학습을 진행하기 위해 Masked Language Model, Nest Sequence Prediction의 두 가지 학습 방식을 이용하였으며, 11개의 자연어 학습 능력 평가 지표에서 SOTA를 달성했다고 합니다.&lt;/p&gt;

&lt;p&gt;그럼 시작하겠습니다!&lt;/p&gt;
&lt;h2 id=&quot;feature-based-and-fine-tuning&quot;&gt;Feature-based and Fine-tuning&lt;/h2&gt;
&lt;p&gt;언어 모델을 pre-training 방식으로 학습하여 여러 가지 task에 적용하는 것은 효율성과 성능의 측면에서 우수했기 때문에 자연어 분야의 학습 전략으로 널리 활용되어 왔습니다. 모델을 pre-training 한 뒤에, task에 알맞게 이용하는 방식에는 크게 두 가지가 있습니다.&lt;/p&gt;

&lt;p&gt;우선 Feature-based 방식은 pre-training 과정에서 각 단어에 대한 representation이 완벽하게 학습되었다고 가정하기 때문에, task-specific한 재학습 과정에서 pre-trained network의 parameter들을 바꾸지 않습니다. 대신에 pre-trainied network를 통해 얻은 Embedding vector를 task에 맞는 network에 통과시켜서 그 network의 parameter를 학습시키는 방향으로 task를 수행합니다.
반면에 Fine-tuning 방식은 downstream task를 학습할 때 pre-trained network의 parameter를 전부 조정해줍니다. Feature-based 방식에 비해 Network capacity가 커지기 때문에 일반적으로 높은 정확도를 보이지만, 계산량도 마찬가지로 늘어난다는 단점이 있습니다.&lt;/p&gt;

&lt;p&gt;BERT는 Fine-tuning 방식을 기반으로 한 모델입니다. BERT를 각 downstream task 별로 어떻게 fine-tuning 했는지는 아래에서 자세히 다루겠습니다.&lt;/p&gt;
&lt;h2 id=&quot;bert-model-architecture&quot;&gt;BERT Model Architecture&lt;/h2&gt;
&lt;p&gt;BERT는 Vaswani의 논문에서 발표된 Transformer의 Encoder 구조를 그대로 차용하였습니다. 뒤에서 자세히 설명드리겠지만 encoder의 self-attention 메커니즘은 병렬적으로 output을 생성하기 때문에, 두 방향(bidirectional)에 대한 추론을 통해 학습할 수 있습니다. 이는 BERT가 기존의 단방향 모델(OpenAI GPT) 또는 제약이 있는 양방향 모델(Bi-LSTM을 활용한 ELMo 등)보다 좋은 성과를 내는 데에 큰 기여를 하게 됩니다.&lt;/p&gt;

&lt;p&gt;논문에서는 두 개의 모델을 공개하였는데, transformer layer 개수(12/24), hidden size(768/1024), self-attention head의 개수(12/16)에 따라 BERT base 모델과 BERT large 모델로 구분하였습니다. 각각의 parameter 개수는 110M/340M으로 BERT large가 약 세 배 정도의 capacity를 가지고 있습니다.&lt;/p&gt;

&lt;p&gt;BERT는 단일 문장에 대한 downstream task 뿐만 아니라 두 개 이상의 문장에 대해서도 잘 작동할 수 있도록 input의 형태를 변형하였습니다. BERT의 input인 sequence는 한 개 또는 두 개 이상의 문장으로 구성되었습니다. 각 sequence은 항상 [CLS] token으로 시작되는데, 이 [CLS] token에 대한 output은 classification이 필요한 task의 경우 그 probability value로 이용하였습니다. 만약 한 sequence가 두 개 이상의 문장으로 구성된 형태라면 첫 번째 문장과 두 번째 문장 사이에 [SEP] token을 넣어서 구분해주었습니다. 또한, 두 문장을 구분하기 위한 추가적인 장치로 첫 번째 문장과 두 번째 문장에 서로 다른 sentence embedding을 더해주었습니다.&lt;/p&gt;

&lt;p&gt;문장 구성에 대한 이해를 위해 downstream task 몇 가지를 예를 들어 설명하겠습니다. 만약 한 문장 안에 하나의 빈칸을 뚫어 그 단어를 예측하는 형태의 task는, input으로 하나의 문장이 들어가고 output으로는 한개의 단어가 나오면 충분할 것입니다. 하지만 어떤 문단과 그에 대한 질문의 답을 찾는 복잡한 언어 추론 형태의 task에서는, 질문이 input의 첫 번째 문장으로 들어가고 문단이 input의 두 번째 문장으로 들어가며 두 문장에 대한 명확한 구분이 필요할 것입니다. 또한 output으로는 질문에 대한 답에 해당되는 문단의 위치를 start/end token으로 얻을 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/201102-BERT/input-representation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과적으로 BERT의 input representation은 token embedding, positional embedding, segment embedding의 합으로 구성됩니다. 우선 token embedding은 original input이 WordPiece Tokenization을 통해서 변환된 결과입니다. 또한 Transformer 논문에서 input에 순서 정보를 반영하기 위해서 활용한 positional embedding을 BERT에서도 마찬가지로 더해주었습니다. 마지막으로 두 개 이상의 문장이 input으로 들어올 수 있기 때문에 이를 구분하기 위한 segment embedding을 더해주었습니다.&lt;/p&gt;
&lt;h2 id=&quot;pre-training-strategy&quot;&gt;Pre-training Strategy&lt;/h2&gt;
&lt;p&gt;BERT의 pre-training에는 중요한 두 가지의 unsupervised task가 활용되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Masked Language Model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;자연어를 잘 이해하고 있는 모델을 얻기 위해서는, 양방향 학습을 하는것이 아주 중요하다고 알려져 있습니다. 하지만 이전까지 대부분의 모델들은 LTR(Left to Right) 또는 RTL(Right to Left)이라고 불리는 단방향 학습이나 Bi-LSTM의 output을 이어붙이는 불완전한 양방향 학습을 통해 얻어지곤 했었습니다. BERT는 Transformer 구조와 Masked LM을 활용하여 multi-layer의 완벽한 양방향 학습을 구현하였습니다.&lt;/p&gt;

&lt;p&gt;Masked Language Model은 문장의 일부분을 masking token으로 치환해서 input으로 넣어주고, 해당 mask token을 원래 단어로 올바르게 복원하도록 학습하는 전략입니다. BERT에서는 문장의 모든 토큰 중 15%를 임의로 선택해 치환하였습니다.&lt;/p&gt;

&lt;p&gt;하지만 이 과정에서 발생할 수 있는 문제가 있습니다. 학습 과정에서는 문장의 일부가 Mask 토큰으로 바뀌어 있는 input을 거의 대부분 보게 되지만, 실제 downstream task에 적용할 때는 Mask 토큰이 없는 문장을 주로 보게 됩니다. 따라서 training과 test 환경의 mismatch가 발생하여 성능이 저하됩니다.&lt;/p&gt;

&lt;p&gt;이를 해결하기 위해서 논문에서는 15%의 확률로 선택된 토큰들에 대해서, (1) 80%는 [Mask] 토큰으로 변경하고, (2) 10%는 다른 임의의 토큰으로 변경하고, (3) 10%는 원래 토큰으로 그대로 두는 전략을 이용하였습니다. 이렇게 전혀 다른 토큰을 추가함으로써 모델의 학습이 방해될 수 있다는 지적에 대해, 저자는 전체 토큰의 1.5%의 만에 해당되기 때문에 큰 영향이 없을 것이라고 답했으며 실제 실험을 통해 증명하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/201102-BERT/ablation-mask.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MLM에 대한 예시를 몇개 보여드리면, 기존의 “My dog is hairy”라는 문장에 대해 4번째 토큰이 선택되었다면, 해당 문장은
(1) 80%의 확률로 “My dog is [Mask]”
(2) 10%의 확률로 “My dog is apple”
(3) 10%의 확률로 “My dog is hairy”
로 변환될 수 있습니다.&lt;/p&gt;

&lt;p&gt;BERT와 비교되는 유명한 pre-trained language representation 모델들은 단방향 학습이나 불완전한 양방향 학습을 통해 생성되었습니다. 아래는 BERT와 OpenAI GPT, ELMo의 모델 구조를 비교한 그림입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/201102-BERT/elmo-gpt.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 보이듯 완벽한 Bidirectional 구조를 가진 BERT와는 달리, OpenAI GPT는 Transformer decoder 구조를 차용한듯한 왼쪽에서 오른쪽을 향하는 단방향의 구조를 가지고 있습니다. 또한 ELMo 같은 경우에는, 왼쪽에서 오른쪽을 향하는 LSTM과 오른쪽에서 왼쪽을 향하는 LSTM의 output을 concatenate하여 양방향의 특성을 모두 가지는 representation을 생성하기 위한 구조를 보여주었습니다. 다만 두 LSTM의 결과를 이어붙인 것에 지나지 않기 때문에 완전한 양방향 학습이라고 보기는 어려우며, 계산량도 매우 많고 느리다는 단점이 있습니다. 따라서 Layer를 이어붙여서 깊게 쌓을 수 없고, 높은 성능을 보여주기 어렵게 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Next Sentence Prediction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Question and Answering(QA) 또는 Natural Language Inference(NLI) 등 몇 개의 downstream task는 두 문장 사이의 관계를 이해해야만 해결할 수 있습니다. 언어 모델이 문장 사이의 관계를 학습할 수 있게 하기 위해서 BERT는 NSP라는 학습 전략을 활용하였습니다. NSP는 corpus에서 A와 B라는 두 개의 문장을 고르되, 50%는 A와 B가 내용적으로 연결되게 선택하고 나머지 50%는 A와 B가 내용적으로 전혀 관련이 없게 선택합니다. 각각은 IsNext와 NotNext라는 binary output으로 labeling한 뒤 이를 예측하게끔 언어 모델을 학습시킵니다.&lt;/p&gt;

&lt;p&gt;BERT의 NSP 정확도는 최종적으로 97~98%이었으며, 꽤나 높은 문장 간의 이해도를 보이게 됩니다. 이처럼 쉽고 간단한 NSP 학습 전략은 QA와 NLI 등의 downstream task 성능도 크게 향상시켜주었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pre-training data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BERT는 pre-training corpus로 800M 개의 단어로 구성된 BooksCorpus와 2,500M개의 단어로 구성된 English Wikipedia dataset을 활용했습니다. (list, table, header 등은 학습에서 제외하였습니다.)&lt;/p&gt;
&lt;h2 id=&quot;fine-tuning-bert&quot;&gt;Fine-tuning BERT&lt;/h2&gt;
&lt;p&gt;Pre-training된 BERT 모델은 fine-tuning을 통해 downstream task에 적용하였습니다. Fine-tuning은 BERT 모델에 task-specific한 input-output 데이터를 넣고 end-to-end로 모든 parameter를 학습하였습니다. Pre-training 과정에 비해 훨씬 더 가볍게 진행되었으며, Cloud TPU 1개로 1시간 정도 학습하였습니다.&lt;/p&gt;

&lt;p&gt;논문에서는 BERT의 성능을 검증하기 위해 11개의 downstream task에 대해 fine-tuning을 진행했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GLUE
&lt;img src=&quot;assets/images/201102-BERT/result-glue.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;8개의 task로 구성된 The General Language Understanding Evaluation(GLUE) task에 대해서 SOTA의 성능을 보여주었다. 모든 GLUE task에 대해 32의 batch size로 3 epoch만큼 fine-tuning 해주었으며, [CLS] 토큰의 output을 마지막 classification layer의 input으로 활용하여 K개의 class에 대해 분류했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SQuAD
&lt;img src=&quot;assets/images/201102-BERT/result-squad.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SQuAD는 The Stanford Question Answering Dataset의 약자로 100k개 이상의 질문-정답 쌍으로 구성되어 있습니다. 질문과 정답을 포함한 Wikipedia 문단을 input으로 넣으면, 문단 내의 정답 text 위치를 찾아내어야 합니다. BERT는 위에서 설명한 NSP 전략을 활용해 문장 사이의 관계를 이해하도록 학습되었기 때문에, SQuAD에 대해서도 SOTA의 성능을 보여줄 수 있었습니다.&lt;/p&gt;

&lt;p&gt;SQuAD 2.0은 정답이 없을 확률에 대해서도 label이 되었는데, 이 또한 마찬가지로 BERT는 SOTA의 성능을 보여주었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SWAG
&lt;img src=&quot;assets/images/201102-BERT/result-swag.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SWAG는 The Situations With Adversarial Generations의 약자로 113k개의 문장 쌍으로 구성되어 있습니다. 한 문장이 주어질 때, 뒤에 나오기에 적절한 문장을 4개의 보기 중에 선택하는 형태로 구성되었습니다. [CLS] 토큰을 활용하여 4개의 선택지에 대한 score를 얻어서 평가하였습니다. BERT는 SWAG 데이터셋에 대해서도 마찬가지로 SOTA의 성능을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/201102-BERT/fine-tuning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;ablation-studies&quot;&gt;Ablation Studies&lt;/h2&gt;

&lt;p&gt;BERT의 성능은 다양한 downstream task들에서 SOTA의 수준으로 확인되었습니다. 그렇다면 앞에서 제안한 BERT의 어떤 특징들이 우수한 성능을 발휘할 수 있게 해준걸까요? 논문에서는 Ablation study를 통해 다양한 장치들의 역할을 분석하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pre-training Strategies&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BERT는 MLM과 NSP라는 두 개의 Task로 Pre-training 되었습니다. 논문에서는 각각의 task가 얼마나 중요한지를 보여주기 위해 NSP를 없애고 학습시켜보기도 하고, NSP를 없애고 단방향으로의(LTR) 학습을 진행해보기도 하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/201102-BERT/ablation-pretraining.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;NSP를 없애자 GLUE와 SQuAD의 성능이 동시에 크게 저하되었습니다. 문장 간의 이해도를 높이는 데 NSP가 중요한 역할을 하고 있으며, 일반적인 Language understanding에도 영향을 미치는 것으로 보입니다.&lt;/p&gt;

&lt;p&gt;또한 MLM을 통한 bidirectional 학습에서 LTR의 단방향 학습으로 변경했을 때에는 SQuAD의 성능이 급격히 저하되었습니다. SQuAD는 단방향 토큰 추론에 대한 task가 아니기 때문에 방향성이 제한됨에 따라 성능이 저하되는 것으로 추측할 수 있을 것 같습니다. 저자는 이를 보완하기 위해서 Bi-LSTM 구조를 모델 위에 얹어서 학습했는데, SQuAD의 성능은 향상시켜주었지만 일반적인 GLUE 결과를 저하시켰습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model Size&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BERT 모델의 크기와 fine-tuning task의 정확도 간의 관계를 확인하기 위한 ablation study도 진행되었습니다. 다양한 layer 개수, hidden unit의 크기, attention head의 개수의 BERT 모델들이 같은 조건 하에서 학습되었습니다. 결과는 널리 알려진 바와 같이 모델의 크기가 커질수록 모델 capacity가 커지며 성능이 향상되었습니다. 또한 큰 capacity의 모델을 pre-training 한 경우에는 아주 작은 scale의 task에 대해서도 좋은 성능을 보여주었습니다. 이는 task의 scale이 아주 작은 경우에 BERT의 효용성이 높다는 의미인데, task-specific한 모델을 설계해서 scratch부터 학습하는 것보다 충분한 pre-training을 통해 얻은 general representation을 initial parameter로 fine-tuning을 하는 것이 더 좋은 성능을 보여주기 때문입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Feature-based BERT&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;기존의 BERT는 downstream task에 대해 fine-tuning 방식으로 학습하였습니다. 하지만 fine-tuning 방식은 모델의 구조를 크게 바꾸지 않기 때문에 모든 경우의 downstream task를 represent하기 어렵고, 모든 parameter를 update하므로 계산량도 많다는 단점이 있습니다. 때문에 ELMo와 같은 feature-based approach로 BERT를 활용했을 때 결과가 어떨지에 대해 ablation study가 진행되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/201102-BERT/ablation-feature.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;각 단어의 Entity를 찾는 NER task에 대해 다양한 방식의 feature-based 학습을 진행했는데, SOTA와 비슷한 성능을 보여주었습니다. 이로써 BERT는 fine-tuning과 feature-based approach에 모두 효과적이라는 것이 확인되었습니다.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;BERT는 다양한 NLP task에 대해 SOTA를 달성하면서, 발표 직후부터 지금까지 NLP 분야에 많은 영향력을 끼치고 있는 모델입니다. Bidirectional training을 위해 기존에 활용되지 않던 Masked Model Language를 도입했고, Next Sentence Prediction task를 통해 문장 사이의 관계도 효과적으로 학습하였습니다. 최근까지도 BERT를 기반으로 하거나 BERT를 뛰어넘기 위해 도전하는 논문들이 계속해서 출간되고 있습니다.&lt;/p&gt;

&lt;p&gt;BERT를 읽다 보니 NLP 관련 연구들에 관심이 더 생기는 것 같습니다. 시간이 되면 NLP 관련 논문들을 더 리뷰해보겠습니다. 읽어주셔서 감사합니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.04805ㅠ&quot;&gt;https://arxiv.org/abs/1810.04805&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/google-research/bert&quot;&gt;https://github.com/google-research/bert&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="nlp" /><category term="nlp" /><summary type="html">원문 : Devlin, Jacob, et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” arXiv preprint arXiv:1810.04805 (2018).</summary></entry><entry><title type="html">EfficientDet - Scalable and Efficient Object Detection 리뷰</title><link href="https://rauleun.github.io/EfficientDet" rel="alternate" type="text/html" title="EfficientDet - Scalable and Efficient Object Detection 리뷰" /><published>2020-09-26T09:00:00+09:00</published><updated>2020-09-26T09:00:00+09:00</updated><id>https://rauleun.github.io/EfficientDet</id><content type="html" xml:base="https://rauleun.github.io/EfficientDet">&lt;p&gt;원문 : &lt;a href=&quot;https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.pdf&quot;&gt;Tan, Mingxing, Ruoming Pang, and Quoc V. Le. “Efficientdet: Scalable and efficient object detection.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/main-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오늘 소개드릴 논문은 Google Research에서 2020년 CVPR에 발표한 &lt;strong&gt;&lt;em&gt;Efficientdet: Scalable and efficient object detection&lt;/em&gt;&lt;/strong&gt; 논문에 대한 리뷰입니다.&lt;/p&gt;

&lt;p&gt;이 논문은 주어진 제약 조건(메모리 및 레이턴시) 아래에서 가장 효율적인 모델 구조를 찾아주는 &lt;a href=&quot;https://arxiv.org/pdf/1905.11946.pdf&quot;&gt;EfficientNet&lt;/a&gt;을 object detection 분야에 접목시킨 연구를 다루고 있으며, 기존의 여러 모델과 비교하였을 떄 성능 및 효율성 측면에서 아주 뛰어난 결과를 보여주었습니다.&lt;/p&gt;

&lt;p&gt;EfficientNet 구조를 backbone으로 하며, 그 논문에서 제안한 compound scaling을 활용해 여러 capacity의 모델을 제안했기 때문에 EfficientNet 논문을 읽고서 보시는 것을 추천드립니다. 그럼 시작하겠습니다!&lt;/p&gt;
&lt;h2 id=&quot;efficientdet-architecture&quot;&gt;EfficientDet Architecture&lt;/h2&gt;
&lt;p&gt;전통적으로 object detection을 수행하기 위한 모델 구조는 region-of-interest(ROI)를 제안하는 부분의 유무에 따라 one-stage와 two-stage로 구분합니다. 일반적으로 one-stage가 학습 및 추론 속도가 빠르고 간단한 구조를 가진다는 장점이 있다면, two-stage는 복잡한 구조를 가지지만 높은 정확성 및 AP 값을 가진다는 장점이 있습니다. 본문에서 소개한 EfficientDet은 ROI proposal 단계가 없으면서도 모델의 구조 최적화를 통해 높은 성능을 보여줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/efficientdet-architecture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;EfficientDet은 크게 CNN backbone, BiFPN, Class/Bbox prediction의 세 부분으로 구성되어 있습니다. 하나씩 살펴보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CNN backbone (EfficientNet)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CNN backbone으로는 SOTA의 이미지 분류 성능을 보여준 EfficientNet이 사용되었습니다. EfficientNet은 convolution 연산 기반 모델의 성능을 높이기 위해 모델의 width(channel 개수), depth(layer 개수), resolution(input 크기)를 동시에 늘리는 compound scaling을 적용하였습니다. 또한 세 가지 hyperparameter를 일정 비율로 키워 memory, latency 등의 자원 제약에 따라 모델의 capacity를 증가하였습니다. 결과적으로 EfficientNet은 같은 자원을 활용한 ResNet이나 Inception, DenseNet보다 훨씬 높은 성능을 보여주었습니다. EfficientDet은 이러한 EfficientNet을 backbone으로 하여 객체의 특징을 잘 나타내주는 여러 scale의 feature map을 추출하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Weighted Bidirectional FPN&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;전통적인 CNN 기반의 one-stage 모델들은 하나의 feature map에서 object detection을 수행했기 때문에 다양한 크기의 객체를 검출하지 못하는 문제가 있었습니다. Feature Pyramid Network(FPN) 구조는 이를 해결하기 위해 등장하였습니다. FPN은 여러 layer에서 다양한 scale의 feature map을 추출하고, 각각으로부터 object detection을 수행하기 때문에 다양한 크기의 객체 검출이 가능했습니다. 또한 여러 resolution의 feature map을 더해주는 multi-scale feature fusion을 통해 성능을 높여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/fpn-architectures.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Multi-scale feature fusion 구조는 FPN에서 처음 제안된 이후에 더 높은 성능을 실현하기 위해 다양하게 변화하였습니다. FPN이 top-down 방식으로 서로 다른 두 scale의 feature map을 더해주었다면, PANet에서는 기존 FPN 구조에 bottom-up path aggregation 구조를 추가하여 information flow를 다양화해주었습니다. 또한 NAS-FPN에서는 강화학습을 이용한 수 천 시간의 학습을 통해 성능과 효율성이 동시에 뛰어난 cross-scale connection 구조를 제안하였습니다. 
&lt;img src=&quot;assets/images/200926-EffiDet/bifpn-architecture.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
EfficientDet은 multi-scale feature fusion을 위해 기존에 제안된 FPN류 구조들 중 높은 성능을 내는 PANet을 몇 가지 부분에서 수정하였습니다. 우선 feature-fusion 없이 하나의 input만을 받는 top-down의 맨 위, 맨 아래 node를 제거하였습니다. 또한 같은 level에 있는 input feature를 output에 더해주는 skip-connection을 추가하여, 적은 수의 계산량으로 feature fusion을 수행할 수 있도록 설계하였습니다. 마지막으로 구성한 bi-directional(top-down &amp;amp; bottom-up) 구조를 하나의 블럭으로 두고 여러 번 반복해 high-level feature fusion을 가능하게 만들었습니다. BiFPN 블럭의 반복 횟수는 compound scaling을 통해 최적화하였습니다.&lt;/p&gt;

&lt;p&gt;EfficientDet은 feature map를 더하는 과정도 개선하였습니다. 기존의 multi-scale feature fusion 과정에서는 서로 다른 여러 scale의 feature map을 단순하게 같은 비율로 더해주었습니다. 하지만 EfficientDet에서는 서로 다른 resolution을 가진 input으로부터 얻어진 feature map들이기 때문에 더해지는 과정에서 output에 기여하는 정도가 다를 수 있다고 판단하여, 이를 반영하여 weight를 곱해서 더해주는 방법을 제안하였습니다. 각 feature map의 weight는 다른 변수와 마찬가지로 학습을 통해서 최적화하였고, 계산의 효율성을 위해 feature 단위의 스칼라 값으로 정의하였습니다. 또한 feature fusion을 하는 과정에서 weight의 총합을 1로 normalize 해주었는데, latency cost를 줄이기 위해 softmax layer 대신 단순히 weight들을 더한 값에서 각 weight의 비율을 계산하는 fast-normalization fusion 방식을 활용하였습니다.&lt;/p&gt;

&lt;p&gt;마지막으로 parameter 개수를 줄이기 위해 feature fusion 과정에서 발생하는 convolution 연산들을 모두 depthwise-convolution으로 대신하였고, batch normalization과 activation layer를 convolution 뒤에 추가하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Class/Bbox prediction layer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각각 여러 겹의 Convolution layer을 이용해 class 정보와 bounding box 좌표를 예측하였습니다. 이 때 convolution layer의 개수는 compound scaling을 통해 최적화하였습니다.&lt;/p&gt;
&lt;h2 id=&quot;compound-scaling&quot;&gt;Compound Scaling&lt;/h2&gt;
&lt;p&gt;이 논문에서 여러 번 반복해서 강조하는 EfficientDet의 설계 목표는 자원의 제약(resource constraint)이 주어질 때 가장 효율적인 모델 구조를 찾는 것입니다. EfficientDet에서는 다양한 resource constraint 상황을 대비하기 위해, baseline 구조를 잡고, 구조를 구성하는 각 요소의 크기를 동시에 늘리는 compound scaling을 이용하여 모델의 크기를 키워나갔습니다. EfficientNet에서는 이러한 compound scaling 과정을 grid search를 통해서 수행하여 최적의 compound coefficient를 찾았지만, EfficientDet은 훨씬 더 큰 차원의 모델이기에 grid search 대신에 heuristic 기반의 scaling approach를 활용하였습니다. 결과적으로 얻은 8개의 EfficientDet 모델에 대한 scaling configuration은 아래와 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/scale-parameters.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Dataset&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;EfficientDet은 COCO2017의 object detection 데이터셋을 활용하여 각각 약 118,000장과 5,000장의 이미지를 이용해 학습 및 검증되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Loss function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;대부분의 object detection 모델과 마찬가지로, EfficientDet도 여러가지 loss function을 활용하였습니다. Class predictor에 대한 classification loss와 bbox predictor에 대한 L1 및 IOU loss의 합을 loss function으로 정의하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;그 외 details&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Stochastic gradient descent(SGD) optimizer를 이용하였습니다. 또한 activation function으로는 ReLU를 대체하기 위해 Google에서 고안한 swish activation을 이용하였습니다. Sigmoid 함수에 일차함수를 곱한 형태입니다.&lt;/p&gt;

&lt;p&gt;각 모델은 32개의 TPU v3 코어를 활용하여 코어 당 4개의 이미지를 학습했고, 결과적으로 128의 batch size를 가집니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Segmentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;EfficientDet에 약간의 구조를 추가하여 semantic segmentation을 학습해보았는데, ResNet 또는 Xception 기반의 DeepLabV3보다 성능이 뛰어났다고 합니다. 모델 구조는 D4 EfficientDet에 backbone의 level-2 feature를 받아 pixelwise classification하는 layer를 추가하였습니다.&lt;/p&gt;
&lt;h2 id=&quot;result&quot;&gt;Result&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/result-params.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 표는 다른 object detection 모델들과 비교한 EfficientDet의 성능을 나타내는데, 압도적인 결과를 보여주고 있습니다. EfficientDet은 다른 모델들과 비슷한 Parameter 개수나 CPU/GPU latency의 조건에서 뛰어난 AP성능을 보여주었습니다. 실험을 할 때, 다른 네트워크에 대해서는 공정한 비교를 위해 convolution 연산을 모두 depthwise로 바꿔주었다고 합니다. 모델의 크기를 늘리는 데에는 한계가 있기 떄문에, 주어진 모델 capacity에서 뛰어난 효율성을 보여주어야 한다는 EfficientDet의 철학이 제대로 반영된 결과라고 할 수 있을 것 같습니다. 유사한 크기의 다른 네트워크에 대한 스펙을 아래 표로 정리하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/result-ap.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;논문에서는 여러가지 ablation study를 진행하였는데, 우선 EfficientDet 내의 EfficientNet과 BiFPN을 각각 ResNet과 FPN으로 바꾼 모델과 성능을 비교해보았습니다. 각각을 다른 구조로 치환한 두 실험에서 모두 AP가 3~4정도 낮아진 걸로 보아 두 구조 모두 성능에 중요한 역할을 하는 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/ablation-backbone-fpn.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 BiFPN 구조 우수성을 보여주기 위해, EfficientDet을 다른 여러 multi-scale feature fusion 방식으로 바꾸어 결과를 비교하였습니다. 마찬가지로 공정한 비교를 위해 FPN 블럭을 반복하여 parameter 개수를 비슷하게 맞춰주었습니다. 결과에서 BiFPN은 기존의 방법 중 가장 뛰어난 성능을 내던 PANet의 AP를 따라잡거나 뛰어 넘는 모습을 보여주었으며, 훨씬 작은 수의 메모리와 FLOPs를 이용하며 효율성 측면에서 압도적인 모습을 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/ablation-fpn.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;학습이 진행됨에 따라 multi-scale feature fusion에 사용하는 weight 값의 변화 과정을 softmax와 fast normalization fusion 각각을 사용했을 때에 대해 그려보았습니다. 두 실험에서 모두 모델이 데이터에 따라 어떤 resolution의 input을 강조해야하는지를 잘 학습하고 있는 것 같았고, 결과적으로 유사한 weight 값으로 수렴하였음을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/ablation-weight1.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;assets/images/200926-EffiDet/ablation-weight2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;EfficientDet 구조에서 각 구성 요소의 hyperparameter를 동시에 높여서 학습시키는 compound scaling 도 각각의 hyperparameter를 하나씩 키워서 학습시킬 때보다 훨씬 더 높은 AP 결과를 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/200926-EffiDet/result-compound-scaling.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;EfficientDet은 발표일 기준 COCO object detection task에 대해 SOTA의 성능 및 효율성을 보여준 획기적인 논문입니다. 실제로 공식 github 코드를 받아 자율주행 및 문자인식 데이터셋으로 fine-tuning하여 사용해보았는데, 다른 모델들과 비교하여 꽤나 뛰어난 성능을 보여주었습니다. 또한 각자의 자원 제약 조건(GPU 메모리 크기, 최대 추론 시간)에 맞는 최적의 모델을 선택할 수 있기 때문에 제가 사용하고 있는 GPU 메모리에 맞는 모델을 능동적으로 결정할 수 있어 효용성이 크다고 느꼈습니다.
다만 Compound scaling을 적용함에 있어서 일정한 비율로 scale-up을 해줄 때 좀 더 최적화된 heuristic 또는 규칙이 있을 수도 있겠다는 생각이 듭니다. 어떤 모델이 EfficientDet의 성능 또는 효율성을 뛰어넘을 수 있을지 기대하며 이번 리뷰는 마치겠습니다. 읽어주셔서 감사합니다 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고 문헌 및 출처&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1905.11946.pdf&quot;&gt;https://arxiv.org/pdf/1905.11946.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.pdf&quot;&gt;https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/google/automl/tree/master/efficientdet&quot;&gt;https://github.com/google/automl/tree/master/efficientdet&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Hyunsung Eun</name></author><category term="CV" /><category term="CV" /><summary type="html">원문 : Tan, Mingxing, Ruoming Pang, and Quoc V. Le. “Efficientdet: Scalable and efficient object detection.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.</summary></entry></feed>